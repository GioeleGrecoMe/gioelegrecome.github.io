<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Adaptive Room Equalizer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap');
        body { font-family: 'Inter', sans-serif; }

        /* Custom Checkbox for Band Toggles */
        .toggle-checkbox:checked {
            background-color: #10b981; /* Emerald 500 */
            border-color: #10b981;
        }
        .toggle-checkbox:checked:after {
            transform: translateX(100%);
            border-color: white;
        }

        .band-disabled .fill-bar {
            background: #4b5563 !important; /* Gray 600 */
            opacity: 0.3;
        }

        /* Vertical Slider Styling for Calibration */
        input[type=range][orient=vertical] {
            writing-mode: bt-lr; /* IE */
            -webkit-appearance: slider-vertical; /* WebKit */
            width: 8px;
            height: 100%;
            padding: 0 5px;
        }

        /* Custom Webkit Slider for Calibration */
        .calib-slider {
            -webkit-appearance: none;
            width: 6px;
            height: 100px;
            background: #374151;
            outline: none;
            border-radius: 3px;
            cursor: pointer;
        }
        .calib-slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 16px;
            height: 16px;
            background: #60a5fa; /* Blue 400 */
            border-radius: 50%;
            border: 2px solid #1e3a8a;
            cursor: pointer;
            box-shadow: 0 0 5px rgba(0,0,0,0.5);
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 h-screen flex flex-col overflow-hidden">

    <!-- Header -->
    <header class="px-6 py-4 border-b border-gray-800 bg-gray-900 z-10 flex justify-between items-center shadow-lg flex-shrink-0">
        <div>
            <h1 class="text-xl font-bold text-emerald-400 tracking-tight">Adaptive Room EQ (12-Band)</h1>
            <p class="text-xs text-gray-500 font-mono">Loop: Source -> Speakers -> Room -> Mic -> Correction</p>
        </div>
        <div class="flex items-center gap-4">
            <div class="flex flex-col items-end text-right mr-4">
                <span class="text-[10px] uppercase text-gray-500 font-bold">Latency / Sync</span>
                <span id="syncStatus" class="text-xs text-blue-400 font-mono">CALCULATING...</span>
            </div>
            <div class="flex flex-col items-end text-right mr-4">
                <span class="text-[10px] uppercase text-gray-500 font-bold">Status</span>
                <span id="systemStatus" class="text-xs text-yellow-500 font-mono">WAITING FOR INPUT</span>
            </div>
            <label class="px-5 py-2.5 bg-emerald-600 hover:bg-emerald-500 rounded-lg text-sm font-semibold transition-all cursor-pointer shadow-lg shadow-emerald-900/20 flex items-center gap-2 group">
                <svg class="w-4 h-4 text-emerald-100" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19V6l12-3v13M9 19c0 1.105-1.343 2-3 2s-3-.895-3-2 1.343-2 3-2 3 .895 3 2zm12-3c0 1.105-1.343 2-3 2s-3-.895-3-2 1.343-2 3-2 3 .895 3 2zM9 10l12-3"></path></svg>
                <span>Play Music File</span>
                <input type="file" id="fileInput" accept="audio/*" class="hidden">
            </label>
        </div>
    </header>

    <!-- Main Interface -->
    <main class="flex-grow flex flex-col relative h-full overflow-hidden">

        <!-- Canvas Visualizer -->
        <div class="relative flex-grow bg-black min-h-[200px]">
            <canvas id="vizCanvas" class="w-full h-full"></canvas>

            <!-- Floating Overlay Information -->
            <div class="absolute top-4 left-6 space-y-2 pointer-events-none">
                <div class="flex items-center gap-2 text-xs font-mono bg-black/50 p-1 rounded backdrop-blur-sm">
                    <span class="w-3 h-3 bg-emerald-500 rounded-sm inline-block"></span>
                    <span class="text-gray-300">Reference (Source File)</span>
                </div>
                <div class="flex items-center gap-2 text-xs font-mono bg-black/50 p-1 rounded backdrop-blur-sm">
                    <span class="w-3 h-3 bg-red-500 rounded-sm inline-block"></span>
                    <span class="text-gray-300">Measured (Mic) [Normalized]</span>
                </div>
            </div>

            <!-- Warning for Headphones -->
            <div id="feedbackWarning" class="hidden absolute bottom-4 right-6 max-w-sm bg-red-900/80 border border-red-500/50 p-3 rounded-lg backdrop-blur text-xs text-red-100">
                <strong>⚠️ Warning:</strong> Ensure you are using speakers so the mic can hear the room.
            </div>
        </div>

        <!-- Adaptive EQ Dashboard -->
        <div class="bg-gray-800 border-t border-gray-700 h-[450px] flex-shrink-0 flex flex-col shadow-[0_-5px_20px_rgba(0,0,0,0.3)] z-20">
            <div class="flex-grow flex flex-row h-full">

                <!-- Controls Side (Left) -->
                <div class="w-64 flex-shrink-0 border-r border-gray-700 p-5 flex flex-col justify-start space-y-6 bg-gray-850 overflow-y-auto">
                    <div>
                        <h3 class="text-sm font-semibold text-gray-300 mb-4">Settings</h3>
                        <div class="flex justify-between text-xs text-gray-400 mb-2 font-mono">
                            <span>Adaptation Speed</span>
                            <span id="speedVal" class="text-emerald-400">Med</span>
                        </div>
                        <input type="range" id="adaptSpeed" min="0.01" max="0.2" step="0.01" value="0.05" class="w-full h-1 bg-gray-600 rounded-lg appearance-none cursor-pointer">
                    </div>

                    <div class="flex items-center justify-between">
                        <span class="text-sm font-semibold text-gray-300">Master EQ</span>
                        <button id="toggleEqBtn" class="w-12 h-6 rounded-full bg-emerald-600 relative transition-all shadow-inner">
                            <div class="w-4 h-4 bg-white rounded-full absolute top-1 right-1 transition-transform"></div>
                        </button>
                    </div>

                    <div class="p-3 bg-blue-900/20 border border-blue-800 rounded text-xs text-blue-300 leading-relaxed">
                        <strong>Mic Calibration:</strong><br>
                        Adjust the top sliders to match your microphone's curve.
                    </div>

                    <div class="p-3 bg-gray-800 border border-gray-700 rounded text-[10px] text-gray-400 font-mono">
                         Signal Sync: <span id="debugDelay">0ms</span><br>
                         Norm Factor: <span id="debugNorm">1.0x</span><br>
                         <span class="text-gray-500">Constraint: Zero-Mean Gain</span>
                    </div>
                </div>

                <!-- Matrix Area (Right) -->
                <div class="flex-grow flex flex-col bg-gray-800 overflow-hidden relative">

                    <!-- Row 1: Calibration (Input) -->
                    <div class="h-1/2 border-b border-gray-700 flex flex-col p-2 relative bg-gray-800/50">
                        <div class="absolute top-2 left-2 text-[10px] font-bold text-blue-400 uppercase tracking-wider bg-gray-900 px-2 py-1 rounded border border-blue-900/50 z-10">
                            Microphone Profile (Calibration)
                        </div>
                        <div id="calibrationContainer" class="flex-grow flex items-end justify-between gap-1 overflow-x-auto pt-6 pb-2 px-2">
                            <!-- Injected Sliders -->
                        </div>
                    </div>

                    <!-- Row 2: Adaptation (Output) -->
                    <div class="h-1/2 flex flex-col p-2 relative">
                        <div class="absolute top-2 left-2 text-[10px] font-bold text-emerald-400 uppercase tracking-wider bg-gray-900 px-2 py-1 rounded border border-emerald-900/50 z-10">
                            System Correction (Active EQ)
                        </div>
                        <div id="bandsContainer" class="flex-grow flex items-end justify-between gap-1 overflow-x-auto pt-8 pb-1 px-2">
                            <!-- Injected Bars -->
                        </div>
                    </div>

                </div>
            </div>
        </div>

    </main>

    <script>
        // --- Configuration ---
        const EQ_BANDS = [
            30, 60, 120, 240, 480,
            960, 1920, 3840, 7680,
            11000, 14000, 18000
        ];

        // --- Audio Context & Nodes ---
        let audioCtx;
        let sourceNode;
        let micNode;
        let alignmentDelayNode; // Delay line for Source Analysis to match Mic Latency

        let filters = [];
        let analyzerSource;  // Delayed Source (Ref for EQ)
        let analyzerMic;     // Mic (Measured)

        let isRunning = false;
        let masterEqEnabled = true;
        let adaptationRate = 0.05;
        let optimizationInterval = null;
        let smoothedNorm = 1.0;

        // State for each band
        let bandStates = EQ_BANDS.map(f => ({
            freq: f,
            gain: 0,        // The active correction gain (System Output)
            calibration: 0, // The user-defined mic offset (User Input)
            enabled: true,  // Optimization Toggle
            elementId: `band-${f}`
        }));

        // UI Elements
        const canvas = document.getElementById('vizCanvas');
        const ctx = canvas.getContext('2d');
        const statusEl = document.getElementById('systemStatus');
        const syncStatusEl = document.getElementById('syncStatus');
        const bandsContainer = document.getElementById('bandsContainer');
        const calibrationContainer = document.getElementById('calibrationContainer');
        const debugDelay = document.getElementById('debugDelay');
        const debugNorm = document.getElementById('debugNorm');

        // --- UI Generation ---
        function initBandUI() {
            bandsContainer.innerHTML = '';
            calibrationContainer.innerHTML = '';

            EQ_BANDS.forEach((freq, index) => {
                const freqLabel = freq >= 1000 ? (freq/1000).toFixed(1) + 'k' : freq;

                // 1. Calibration Slider (Top Row)
                const calibDiv = document.createElement('div');
                calibDiv.className = 'flex flex-col items-center h-full justify-end w-full max-w-[60px] relative';
                calibDiv.innerHTML = `
                    <div class="text-[9px] text-blue-300 font-mono mb-1" id="calib-val-${index}">0dB</div>
                    <div class="relative h-full w-full flex justify-center">
                        <input type="range"
                               min="-15" max="15" step="1" value="0"
                               class="calib-slider -rotate-180"
                               style="writing-mode: vertical-lr; direction: rtl; width: 6px;"
                               oninput="updateCalibration(${index}, this.value)">
                    </div>
                `;
                calibrationContainer.appendChild(calibDiv);

                // 2. Correction Bar (Bottom Row)
                const bandDiv = document.createElement('div');
                bandDiv.className = 'flex flex-col items-center h-full justify-end w-full max-w-[60px] group relative';
                bandDiv.id = `band-container-${index}`;

                bandDiv.innerHTML = `
                    <div class="absolute -top-6 text-[10px] font-mono text-amber-400 opacity-0 group-hover:opacity-100 transition-opacity whitespace-nowrap z-10 bg-gray-900 px-1 rounded">
                        <span id="gain-text-${index}">0.0</span>dB
                    </div>
                    <div class="h-24 w-4 md:w-5 bg-gray-900 rounded-full relative border border-gray-700 overflow-hidden shadow-inner mb-2">
                        <div id="fill-${index}" class="fill-bar absolute bottom-0 w-full bg-gradient-to-t from-emerald-600 to-emerald-400 transition-all duration-300 ease-out opacity-90" style="height: 50%"></div>
                        <div class="absolute top-1/2 w-full h-px bg-white/30"></div>
                    </div>
                    <span class="text-[9px] md:text-[10px] text-gray-400 font-bold mb-1">${freqLabel}</span>
                    <label class="relative inline-flex items-center cursor-pointer">
                        <input type="checkbox" checked class="sr-only peer" onchange="toggleBand(${index}, this.checked)">
                        <div class="w-6 h-3 bg-gray-700 peer-focus:outline-none rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-2 after:w-2 after:transition-all peer-checked:bg-emerald-600"></div>
                    </label>
                `;
                bandsContainer.appendChild(bandDiv);
            });
        }

        function updateCalibration(index, value) {
            bandStates[index].calibration = parseFloat(value);
            const label = document.getElementById(`calib-val-${index}`);
            if(label) label.textContent = (value > 0 ? '+' : '') + value + 'dB';
        }

        function toggleBand(index, isChecked) {
            bandStates[index].enabled = isChecked;
            const container = document.getElementById(`band-container-${index}`);
            if (!isChecked) {
                container.classList.add('band-disabled');
                bandStates[index].gain = 0;
            } else {
                container.classList.remove('band-disabled');
            }
        }

        // --- Audio System ---
        async function initAudioSystem() {
            if (audioCtx) return;
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();

            filters = [];
            EQ_BANDS.forEach(freq => {
                const filter = audioCtx.createBiquadFilter();
                filter.type = 'peaking';
                filter.frequency.value = freq;
                filter.Q.value = 1.4;
                filter.gain.value = 0;
                filters.push(filter);
            });

            // Create Analyzers
            analyzerSource = audioCtx.createAnalyser(); // Delayed Ref
            analyzerMic = audioCtx.createAnalyser();    // Measured

            // WINDOWING CONFIGURATION:
            // Maximize fftSize to get closest to 1.0s window.
            // 32768 samples @ 44.1kHz = ~0.74s (This is the hardware limit for AnalyserNode)
            const MAX_FFT = 32768;

            // Set smoothing low because we are manually hopping slowly
            const smoothing = 0.2;
            analyzerSource.smoothingTimeConstant = smoothing;
            analyzerMic.smoothingTimeConstant = smoothing;

            analyzerSource.fftSize = MAX_FFT;
            analyzerMic.fftSize = MAX_FFT;

            // Alignment Delay Node
            alignmentDelayNode = audioCtx.createDelay(1.0); // Max 1 sec delay
            alignmentDelayNode.delayTime.value = 0.0; // Start at 0

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                micNode = audioCtx.createMediaStreamSource(stream);
                micNode.connect(analyzerMic);

                document.getElementById('feedbackWarning').classList.remove('hidden');
            } catch (e) {
                alert("Microphone access is required.");
                console.error(e);
            }

            // Start Visual Loop (Fast)
            drawVizLoop();

            // Start Optimization Loop (Slow - 0.5s Hop)
            if (optimizationInterval) clearInterval(optimizationInterval);
            optimizationInterval = setInterval(runOptimizationStep, 500);
        }

        document.getElementById('fileInput').addEventListener('change', async (e) => {
            if (!e.target.files.length) return;
            initBandUI();
            await initAudioSystem();

            if (sourceNode) {
                sourceNode.stop();
                sourceNode.disconnect();
            }

            const file = e.target.files[0];
            const arrayBuffer = await file.arrayBuffer();
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

            sourceNode = audioCtx.createBufferSource();
            sourceNode.buffer = audioBuffer;
            sourceNode.loop = true;

            // --- AUDIO GRAPH ROUTING ---

            // Path 1: Source -> Alignment Delay -> AnalyzerSource (EQ Reference)
            sourceNode.connect(alignmentDelayNode);
            alignmentDelayNode.connect(analyzerSource);

            // Path 2: Source -> Filters -> Output
            let currentNode = sourceNode;
            filters.forEach(filter => {
                currentNode.connect(filter);
                currentNode = filter;
            });
            currentNode.connect(audioCtx.destination);

            sourceNode.start();
            isRunning = true;
            statusEl.textContent = "SYSTEM ACTIVE";
            statusEl.className = "text-xs text-emerald-400 font-mono animate-pulse";
        });

        // --- Helper: RMS Calculation ---
        function calculateRMS(timeData) {
            let sum = 0;
            // timeData is Uint8 (0-255), center is 128
            for(let i=0; i<timeData.length; i++) {
                const val = (timeData[i] - 128) / 128.0;
                sum += val * val;
            }
            return Math.sqrt(sum / timeData.length);
        }

        // --- Helper: Cross Correlation to find lag ---
        function findDelayOffset(sourceTime, micTime) {
            let bestOffset = 0;
            let maxCorr = -Infinity;
            // Limit search to first 4096 samples for performance given the huge buffer
            const scanLimit = 4096;
            const searchRange = 500;

            // Pre-normalize centered values
            const src = new Float32Array(scanLimit);
            const mic = new Float32Array(scanLimit);
            for(let i=0; i<scanLimit; i++) {
                src[i] = Math.abs((sourceTime[i] - 128) / 128.0); // Envelope (Rectified)
                mic[i] = Math.abs((micTime[i] - 128) / 128.0);
            }

            for (let lag = 0; lag < searchRange; lag++) {
                let sum = 0;
                // Step 2 for speed
                for (let i = 0; i < scanLimit - lag; i += 2) {
                    sum += src[i] * mic[i + lag];
                }
                if (sum > maxCorr) {
                    maxCorr = sum;
                    bestOffset = lag;
                }
            }
            return bestOffset;
        }

        // --- Optimization Loop (Running every 500ms) ---
        function runOptimizationStep() {
            if (!isRunning || !audioCtx) return;

            const bufferLen = analyzerSource.frequencyBinCount; // 16384 bins
            const timeLen = analyzerSource.fftSize; // 32768 samples (~0.7s)

            const dataSource = new Uint8Array(bufferLen);
            const dataMic = new Uint8Array(bufferLen);
            const timeSource = new Uint8Array(timeLen);
            const timeMic = new Uint8Array(timeLen);

            // 1. Get Time Domain Data
            analyzerSource.getByteTimeDomainData(timeSource);
            analyzerMic.getByteTimeDomainData(timeMic);

            // --- STEP A: ALIGNMENT ---
            const lagSamples = findDelayOffset(timeSource, timeMic);

            if (alignmentDelayNode) {
                const currentDelay = alignmentDelayNode.delayTime.value;
                const frameDuration = 1 / audioCtx.sampleRate;
                const offsetTime = lagSamples * frameDuration;

                // Using a slice for RMS check to be fast
                const rmsS = calculateRMS(timeSource.subarray(0, 1024));
                if (rmsS > 0.05) {
                   const targetDelay = currentDelay + (offsetTime * 0.01);
                   const safeDelay = Math.max(0, Math.min(1.0, targetDelay));
                   alignmentDelayNode.delayTime.value = safeDelay;

                   debugDelay.innerText = (safeDelay * 1000).toFixed(1) + "ms";
                   syncStatusEl.innerText = "SYNCING";
                } else {
                    syncStatusEl.innerText = "SIGNAL LOW";
                }
            }

            // --- STEP B: NORMALIZATION ---
            const rmsSource = calculateRMS(timeSource);
            const rmsMic = calculateRMS(timeMic);

            let normalizationFactor = 1.0;
            if (rmsMic > 0.01 && rmsSource > 0.01) {
                normalizationFactor = rmsSource / rmsMic;
            }
            smoothedNorm = smoothedNorm * 0.9 + normalizationFactor * 0.1;
            debugNorm.innerText = smoothedNorm.toFixed(2) + "x";

            // --- STEP C: GRADIENT DESCENT ---
            analyzerSource.getByteFrequencyData(dataSource);
            analyzerMic.getByteFrequencyData(dataMic);

            const nyquist = audioCtx.sampleRate / 2;
            let totalSource = 0;
            let totalMic = 0;

            // Pass 1: Analysis
            const analysisResults = EQ_BANDS.map(centerFreq => {
                const startFreq = centerFreq / 1.4;
                const endFreq = centerFreq * 1.4;
                const startBin = Math.floor((startFreq / nyquist) * bufferLen);
                const endBin = Math.floor((endFreq / nyquist) * bufferLen);

                let eSource = 0;
                let eMic = 0;
                let count = 0;

                for (let i = startBin; i <= endBin; i++) {
                    if (i < bufferLen) {
                        eSource += dataSource[i];
                        eMic += dataMic[i] * smoothedNorm;
                        count++;
                    }
                }

                eSource = eSource / (count || 1);
                eMic = eMic / (count || 1);

                totalSource += eSource;
                totalMic += eMic;

                return { eSource, eMic };
            });

            // Calculate Global spectral ratio target
            const globalRatio = (totalMic / (totalSource || 1));

            // Gather Gradients
            let gradients = new Array(EQ_BANDS.length).fill(0);
            let activeCount = 0;
            let sumGradients = 0;

            EQ_BANDS.forEach((centerFreq, index) => {
                const { eSource, eMic } = analysisResults[index];

                if (masterEqEnabled && bandStates[index].enabled && eSource > 5) {
                    const normSource = eSource * globalRatio;
                    const calibOffset = bandStates[index].calibration * 2.5;
                    const correctedMic = eMic - calibOffset;

                    const error = correctedMic - normSource;
                    const gradient = error;

                    gradients[index] = gradient;
                    sumGradients += gradient;
                    activeCount++;
                }
            });

            // Zero-Mean Constraint
            const meanGradient = activeCount > 0 ? sumGradients / activeCount : 0;

            // Pass 2: Update
            EQ_BANDS.forEach((centerFreq, index) => {
                if (masterEqEnabled && bandStates[index].enabled) {
                    if (gradients[index] !== 0 || activeCount > 0) {
                        const constrainedGradient = gradients[index] - meanGradient;
                        const scaling = 0.02;
                        bandStates[index].gain -= (constrainedGradient * scaling) * adaptationRate;
                    }
                } else if (!bandStates[index].enabled || !masterEqEnabled) {
                    bandStates[index].gain *= 0.95;
                    if (Math.abs(bandStates[index].gain) < 0.1) bandStates[index].gain = 0;
                }

                bandStates[index].gain = Math.max(-15, Math.min(15, bandStates[index].gain));

                const t = audioCtx.currentTime;
                filters[index].gain.setTargetAtTime(bandStates[index].gain, t, 0.5);

                // Update UI
                const fill = document.getElementById(`fill-${index}`);
                const txt = document.getElementById(`gain-text-${index}`);
                if (fill && txt) {
                    const percent = 50 + (bandStates[index].gain / 30) * 100;
                    fill.style.height = `${Math.min(100, Math.max(0, percent))}%`;
                    if (bandStates[index].gain < -1) {
                        fill.className = 'fill-bar absolute bottom-0 w-full bg-gradient-to-t from-amber-600 to-amber-400 transition-all duration-300 ease-out opacity-90';
                    } else {
                        fill.className = 'fill-bar absolute bottom-0 w-full bg-gradient-to-t from-emerald-600 to-emerald-400 transition-all duration-300 ease-out opacity-90';
                    }
                    txt.innerText = bandStates[index].gain.toFixed(1);
                }
            });
        }

        // --- Visualization Loop (Fast 60fps) ---
        function drawVizLoop() {
            requestAnimationFrame(drawVizLoop);

            // Just redraw based on current buffer state if audioCtx exists
            if (!analyzerSource || !analyzerMic) return;

            // Re-read small frequency data just for viz to keep it snappy?
            // Or use the large buffer. Large buffer is fine.
            const bufferLen = analyzerSource.frequencyBinCount;
            const dataSource = new Uint8Array(bufferLen);
            const dataMic = new Uint8Array(bufferLen);

            analyzerSource.getByteFrequencyData(dataSource);
            analyzerMic.getByteFrequencyData(dataMic);

            drawViz(dataSource, dataMic, smoothedNorm);
        }

        function drawViz(sourceData, micData, normFactor) {
            if (canvas.width !== canvas.clientWidth) {
                canvas.width = canvas.clientWidth;
                canvas.height = canvas.clientHeight;
            }
            const w = canvas.width;
            const h = canvas.height;

            ctx.fillStyle = '#0a0a0a';
            ctx.fillRect(0, 0, w, h);

            const bars = 64;
            const barW = w / bars;
            const step = Math.floor(sourceData.length / bars);

            for (let i = 0; i < bars; i++) {
                let s = 0, m = 0;
                for (let j = 0; j < step; j++) {
                    s += sourceData[i * step + j];
                    m += micData[i * step + j] * normFactor;
                }
                s /= step;
                m /= step;

                const x = i * barW;

                s = Math.min(255, s);
                m = Math.min(255, m);

                const hS = (s / 255) * h * 0.9;
                ctx.fillStyle = '#10b981';
                ctx.globalAlpha = 0.4;
                ctx.fillRect(x, h - hS, barW - 1, hS);

                const hM = (m / 255) * h * 0.9;
                ctx.fillStyle = '#ef4444';
                ctx.globalAlpha = 0.6;
                ctx.fillRect(x + 1, h - hM, barW - 3, hM);
            }

            ctx.globalAlpha = 1.0;
            ctx.strokeStyle = '#333';
            ctx.beginPath();
            ctx.moveTo(0, h/2);
            ctx.lineTo(w, h/2);
            ctx.stroke();
        }

        document.getElementById('adaptSpeed').addEventListener('input', (e) => {
            adaptationRate = parseFloat(e.target.value);
            const labels = ["Slow", "Med", "Fast"];
            const idx = Math.floor((adaptationRate / 0.21) * 3);
            document.getElementById('speedVal').textContent = labels[Math.min(2, idx)];
        });

        document.getElementById('toggleEqBtn').addEventListener('click', () => {
            masterEqEnabled = !masterEqEnabled;
            const btn = document.getElementById('toggleEqBtn');
            const dot = btn.querySelector('div');

            if (masterEqEnabled) {
                btn.classList.add('bg-emerald-600');
                btn.classList.remove('bg-gray-600');
                dot.style.transform = 'translateX(0)';
                statusEl.innerText = "ADAPTIVE EQ ACTIVE";
                statusEl.classList.remove('text-gray-500');
                statusEl.classList.add('text-emerald-400');
            } else {
                btn.classList.remove('bg-emerald-600');
                btn.classList.add('bg-gray-600');
                dot.style.transform = 'translateX(-24px)';
                statusEl.innerText = "EQ BYPASSED";
                statusEl.classList.add('text-gray-500');
                statusEl.classList.remove('text-emerald-400');
            }
        });

        initBandUI();

    </script>
</body>
</html>