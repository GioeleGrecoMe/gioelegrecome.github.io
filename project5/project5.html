<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RHC-ED: Dereverberation via CNNs for Acoustic Source DOA Estimation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Navigation */
        .navigation {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px 0;
            margin-bottom: 20px;
        }

        .nav-home {
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 25px;
            border-radius: 25px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }

        .nav-home:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.2);
        }

        .breadcrumb {
            color: rgba(255, 255, 255, 0.8);
            font-size: 0.9em;
        }

        .breadcrumb a {
            color: rgba(255, 255, 255, 0.9);
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .breadcrumb a:hover {
            color: white;
        }

        header {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(15px);
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
            border-radius: 25px;
            margin: 20px auto;
            padding: 50px;
            text-align: center;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        h1 {
            font-size: 2.8em;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 20px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.3em;
            color: #7f8c8d;
            margin-bottom: 25px;
            font-weight: 300;
        }

        .authors {
            font-size: 1.1em;
            color: #34495e;
            margin-bottom: 15px;
            font-weight: 500;
        }

        .affiliations {
            font-size: 0.95em;
            color: #7f8c8d;
            font-style: italic;
            line-height: 1.5;
        }

        .main-content {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(15px);
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
            border-radius: 25px;
            margin: 20px auto;
            padding: 50px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .section {
            margin-bottom: 50px;
        }

        .section h2 {
            font-size: 2em;
            color: #2c3e50;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 3px solid;
            border-image: linear-gradient(135deg, #667eea, #764ba2) 1;
            display: inline-block;
            font-weight: 600;
        }

        .section h3 {
            font-size: 1.5em;
            color: #34495e;
            margin: 30px 0 20px 0;
            font-weight: 600;
        }

        p {
            margin-bottom: 18px;
            color: #555;
            text-align: justify;
            font-size: 1.05em;
            line-height: 1.7;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.08), rgba(118, 75, 162, 0.08));
            border-left: 5px solid #667eea;
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
            box-shadow: 0 4px 20px rgba(102, 126, 234, 0.1);
        }

        /* Image containers */
        .image-container {
            text-align: center;
            margin: 40px 0;
            padding: 30px;
            background: #f8f9fa;
            border-radius: 20px;
            border: 2px solid #e9ecef;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.05);
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 15px;
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .image-container img:hover {
            transform: scale(1.02);
        }

        .image-caption {
            margin-top: 20px;
            font-style: italic;
            color: #666;
            font-size: 1em;
            line-height: 1.5;
        }

        .architecture-diagram {
            text-align: center;
            margin: 40px 0;
            padding: 30px;
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            border-radius: 20px;
            border: 2px solid #667eea;
            box-shadow: 0 8px 30px rgba(102, 126, 234, 0.1);
        }

        .architecture-diagram h4 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 1.4em;
            font-weight: 600;
        }

        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }

        .result-card {
            background: linear-gradient(135deg, #fff, #f8f9fa);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);
            border: 1px solid #e9ecef;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .result-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.12);
        }

        .result-card h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
            font-weight: 600;
        }

        .metric {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 10px 18px;
            border-radius: 25px;
            display: inline-block;
            margin: 8px 8px 8px 0;
            font-weight: 600;
            font-size: 0.9em;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }

        .code-block {
            background: linear-gradient(135deg, #2c3e50, #34495e);
            color: #ecf0f1;
            padding: 30px;
            border-radius: 15px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            margin: 30px 0;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
            line-height: 1.6;
        }

        .btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 15px 30px;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            text-decoration: none;
            display: inline-block;
            margin: 15px 15px 15px 0;
            font-weight: 600;
            font-size: 1.05em;
            transition: all 0.3s ease;
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.3);
        }

        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 12px 30px rgba(102, 126, 234, 0.4);
        }

        .formula {
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            padding: 25px;
            border-radius: 15px;
            font-family: 'Times New Roman', serif;
            text-align: center;
            margin: 25px 0;
            border: 1px solid #e9ecef;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            font-size: 1.1em;
        }

        .dataset-params {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .param-item {
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            border: 1px solid #e9ecef;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            transition: transform 0.3s ease;
        }

        .param-item:hover {
            transform: translateY(-3px);
        }

        .param-item strong {
            color: #667eea;
            display: block;
            margin-bottom: 8px;
            font-size: 1.1em;
        }

        /* Performance charts placeholders */
        .charts-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .chart-placeholder {
            background: #f8f9fa;
            border: 2px dashed #667eea;
            border-radius: 20px;
            padding: 40px;
            text-align: center;
            min-height: 300px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .chart-placeholder h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .chart-placeholder p {
            color: #666;
            font-style: italic;
        }

        footer {
            text-align: center;
            padding: 40px 0;
            color: rgba(255, 255, 255, 0.9);
            font-size: 0.95em;
            line-height: 1.6;
        }

        ul {
            margin-left: 20px;
            color: #555;
        }

        ul li {
            margin-bottom: 12px;
            line-height: 1.6;
        }

        /* Contribution items styling */
        .contribution-item {
            margin: 20px 0;
            padding: 25px;
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.08), rgba(118, 75, 162, 0.08));
            border-radius: 15px;
            border-left: 5px solid #667eea;
            transition: transform 0.3s ease;
        }

        .contribution-item:hover {
            transform: translateX(5px);
        }

        @media (max-width: 768px) {
            .container {
                padding: 0 15px;
            }

            .navigation {
                flex-direction: column;
                gap: 15px;
                text-align: center;
            }

            header, .main-content {
                margin: 15px auto;
                padding: 30px 20px;
            }

            h1 {
                font-size: 2.2em;
            }

            .results-grid, .charts-container {
                grid-template-columns: 1fr;
            }

            .dataset-params {
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            }

            .chart-placeholder {
                min-height: 250px;
                padding: 30px;
            }
        }

        @media (max-width: 480px) {
            header, .main-content {
                padding: 20px 15px;
            }

            h1 {
                font-size: 1.8em;
            }

            .dataset-params {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Navigation -->
        <div class="navigation">
            <a href="../index.html" class="nav-home">← Back to Portfolio</a>
            <div class="breadcrumb">
                <a href="../index.html">Home</a> / <a href="#projects">Projects</a> / RHC-ED
            </div>
        </div>

        <header>
            <h1>RHC-ED: Dereverberation of Relative Harmonic Coefficients via CNNs for Acoustic Source DOA Estimation</h1>
            <div class="subtitle">A Deep Learning Approach to Enhance Sound Source Localization in Noisy and Reverberant Environments</div>
            <div class="authors">
                <strong>Gioele Greco¹, Silvia Messana¹, Mirco Pezzoli¹, Maximo Cobos², Fabio Antonacci¹</strong>
            </div>
            <div class="affiliations">
                ¹Dipartimento Elettronica Informatica e Bioingegneria, Politecnico di Milano, Italy<br>
                ²Departament d'Informàtica, Universitat de València, Spain
            </div>
        </header>

        <div class="main-content">
            <div class="section">
                <h2>Abstract</h2>
                <div class="highlight-box">
                    <p>Relative Harmonic Coefficients (RHCs) are a promising audio descriptor for Direction of Arrival (DOA) estimation but are vulnerable to noise and reverberation. We introduce <strong>RHC-ED</strong>, a convolutional encoder-decoder architecture that processes noisy and reverberant RHCs, restoring their ideal properties by suppressing unwanted artifacts. Using stacked CNNs, RHC-ED compresses and reconstructs RHCs for improved DOA estimation.</p>
                </div>
                <p>Experiments across diverse acoustic conditions confirm RHC-ED's effectiveness in reducing estimation errors and outperforming recent state-of-the-art methods for source localization, especially using first-order spherical harmonics.</p>
            </div>

            <div class="section">
                <h2>Key Contributions</h2>
                <div class="contribution-item">
                    🎯 <strong>Novel Architecture:</strong> Introduction of RHC-ED, a convolutional encoder-decoder specifically designed for RHC dereverberation
                </div>
                <div class="contribution-item">
                    🔬 <strong>Theoretical Foundation:</strong> Mathematical formulation of RHCs in reverberant environments and their deviation from ideal behavior
                </div>
                <div class="contribution-item">
                    📊 <strong>Comprehensive Evaluation:</strong> Validation on both synthetic datasets and real-world measurements from spherical microphone arrays
                </div>
                <div class="contribution-item">
                    🏆 <strong>Superior Performance:</strong> Significant improvement over existing methods with 90% confidence intervals of 7° vs 31° for competing approaches
                </div>
            </div>

            <div class="section">
                <h2>Spherical Coordinate System</h2>
                <div class="image-container">
                    <img src="spherical_coordinates.png" alt="Spherical Coordinate System" />
                    <div class="image-caption">
                        <strong>Figure 1:</strong> Spherical coordinates system, defined by three components: azimuth φ, inclination θ and radius r. This coordinate system is fundamental for representing sound source positions relative to the spherical microphone array.
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>Methodology</h2>

                <h3>Relative Harmonic Coefficients (RHCs)</h3>
                <p>RHCs are defined as the ratio between spherical harmonic coefficients and the zeroth-order coefficient:</p>
                <div class="formula">
                    β<sub>nm</sub>(k) = α<sub>nm</sub>(k) / α<sub>00</sub>(k)
                </div>
                <p>In ideal conditions, RHCs depend only on the source Direction of Arrival (DOA), making them particularly valuable for localization algorithms. However, in reverberant environments, this ideal property is compromised.</p>

                <h3>RHC-ED Architecture</h3>
                <div class="image-container">
                    <img src="RH-CED.png" alt="RHC-ED Architecture" />
                    <div class="image-caption">
                        <strong>Figure 2:</strong> RHC-ED architecture description, including kernel dimensions. The encoding and decoding architectures are mirrored, except that the latter uses transposed convolutions instead of standard convolutions to upsample the compressed features.
                    </div>
                </div>

                <div class="architecture-diagram">
                    <h4>Convolutional Encoder-Decoder Architecture</h4>
                    <p><strong>Input:</strong> 6 × 256 × 10 tensor (Real & Imaginary parts of β<sub>1,-1</sub>, β<sub>1,0</sub>, β<sub>1,1</sub>)</p>
                    <p><strong>Encoder:</strong> 5 Conv layers with progressive dimensionality reduction</p>
                    <p><strong>Decoder:</strong> 5 Transposed Conv layers for reconstruction</p>
                    <p><strong>Output:</strong> Denoised and dereverberated RHCs</p>
                </div>

                <div class="code-block">
Encoder:
- Conv (5×3, 64) + ReLU
- Conv (5×3, 64) + ReLU
- Conv (5×3, 64) + ReLU
- Conv (3×3, 128) + ReLU
- Conv (3×3, 128) + ReLU

Bottleneck:
- Linear(512) + Dropout(0.3)

Decoder:
- ConvT (3×3, 128) + ReLU
- ConvT (3×3, 128) + ReLU
- ConvT (5×3, 64) + ReLU
- ConvT (5×3, 64) + ReLU
- ConvT (5×3, 64)
                </div>

                <h3>DOA Estimation</h3>
                <p>The DOA is estimated using the unitary vector derived from first-order RHCs:</p>
                <div class="formula">
                    η(k) = [sin(φ)sin(θ), cos(φ)sin(θ), cos(θ)]<sup>T</sup>
                </div>
            </div>

            <div class="section">
                <h2>Dataset & Training</h2>
                <div class="dataset-params">
                    <div class="param-item">
                        <strong>Azimuth (φ<sub>s</sub>)</strong>
                        [0°, 360°]
                    </div>
                    <div class="param-item">
                        <strong>Inclination (θ<sub>s</sub>)</strong>
                        [60°, 130°]
                    </div>
                    <div class="param-item">
                        <strong>Distance</strong>
                        [1.5, 3.5]m
                    </div>
                    <div class="param-item">
                        <strong>Room Size</strong>
                        [4-8] × [5-10] × [3-5]m
                    </div>
                    <div class="param-item">
                        <strong>T₆₀</strong>
                        [0.25, 1.0]s
                    </div>
                    <div class="param-item">
                        <strong>SNR</strong>
                        [5, 60]dB
                    </div>
                </div>
                <p>The dataset consists of synthetic RIRs generated using the SMIR generator with Eigenmike 32-channel spherical microphone array configurations. Speech signals from LibriSpeech were convolved with RIRs to create realistic acoustic scenarios with varying reverberation times and noise levels.</p>
            </div>

            <div class="section">
                <h2>Results</h2>

                <h3>Performance Analysis</h3>
                <div class="charts-container">
                    <div class="chart-placeholder">
                        <img src="AE_vs_T60.png" alt="Synthetic Dataset Results" style="max-width: 100%; height: auto; border: none; box-shadow: none;" />
                        <div class="image-caption">
                            <strong>Figure 3:</strong> AE distribution derived from 50 audio samples from the test set for each T₆₀ with SNR in the whole considered range. Solid lines indicate the mean value across all 50 samples, while shaded regions represent the standard deviation.
                        </div>
                    </div>

                    <div class="chart-placeholder">
                        <img src="AE_histogram.png" alt="Real-world Dataset Results" style="max-width: 100%; height: auto; border: none; box-shadow: none;" />
                        <div class="image-caption">
                            <strong>Figure 4:</strong> Probability density function of the AE distribution obtained from real-world measurements. Bars indicate the probability of AE for each 2° sector, dashed lines indicate the 90% confidence interval.
                        </div>
                    </div>
                </div>

                <div class="results-grid">
                    <div class="result-card">
                        <h4>Synthetic Dataset Performance</h4>
                        <p>Evaluated on 50 samples across different T₆₀ values (0.25-1.0s)</p>
                        <div class="metric">Consistently Superior Accuracy</div>
                        <div class="metric">Robust to Reverberation</div>
                        <p>RHC-ED consistently outperformed both unprocessed RHCs and existing classification-based methods across all reverberation conditions.</p>
                    </div>
                    <div class="result-card">
                        <h4>Real-World Validation</h4>
                        <p>Tested on real measurements from METU SPARG Eigenmike dataset</p>
                        <div class="metric">RHC-ED: 7° (90% CI)</div>
                        <div class="metric">Measured RHCs: 14° (90% CI)</div>
                        <div class="metric">Dwivedi et al.: 31° (90% CI)</div>
                        <p>RHC-ED achieved the lowest angular error with significantly tighter confidence intervals.</p>
                    </div>
                </div>

                <div class="highlight-box">
                    <h3>Key Performance Metrics</h3>
                    <p><strong>Angular Error (AE):</strong> AE(η) = |arccos(∑ᴸₗ₌₁ η(kₗ)ᵀ/L · η_GT)|°</p>
                    <p><strong>Standard Deviation:</strong> Measured across T = 418 time frame estimates per sample</p>
                    <p><strong>Confidence Intervals:</strong> RHC-ED shows 50% reduction in error compared to unprocessed RHCs and 77% reduction compared to competing methods</p>
                </div>
            </div>

            <div class="section">
                <h2>Technical Implementation</h2>
                <h3>Input Features</h3>
                <p>The input consists of time-frequency representations of RHCs limited to order N=1, with each coefficient decomposed into real and imaginary components. The system processes 10 consecutive time frames with 256 frequency bins.</p>

                <h3>Training Strategy</h3>
                <p>The model was trained using Mean Square Error (MSE) loss to minimize the difference between processed RHCs and their ideal anechoic counterparts. A voice activity detector was implemented to discard inactive source frames during evaluation.</p>

                <h3>Advantages over Classification Approaches</h3>
                <ul>
                    <li>Continuous DOA estimation vs. discrete 5° intervals</li>
                    <li>Direct processing of acoustic features rather than classification</li>
                    <li>Better handling of first-order spherical harmonics</li>
                    <li>Superior performance in reverberant conditions</li>
                </ul>
            </div>

            <div class="section">
                <h2>Future Directions</h2>
                <p>The RHC-ED framework opens several avenues for future research:</p>
                <ul>
                    <li><strong>Higher-Order Extensions:</strong> Extending to higher-order spherical harmonics for improved spatial resolution</li>
                    <li><strong>Multi-Source Scenarios:</strong> Adapting the architecture for simultaneous localization of multiple sources</li>
                    <li><strong>Real-Time Implementation:</strong> Optimizing the network for real-time processing applications</li>
                    <li><strong>Transfer Learning:</strong> Investigating domain adaptation for different acoustic environments</li>
                </ul>
            </div>
            <section id="references">
            <h2>References</h2>
            <div class="reference">[1] M. Cobos, F. Antonacci, A. Alexandridis, A. Moucharis, and B. Lee, "A survey of sound source localization methods in wireless acoustic sensor networks," Wireless Communications and Mobile Computing, vol. 2017, no. 1, p. 3956282, 2017.</div>
            <div class="reference">[2] W. Shi, J. Huang, and Y. Hou, "Fast doa estimation algorithm for mimo sonar based on ant colony optimization," Journal of Systems Engineering and Electronics, vol. 23, no. 2, pp. 173-178, 2021.</div>
            <div class="reference">[3] Y. Wu, C. Li, Y. T. Hou, and W. Lou, "Real-time doa estimation for automotive radar," in 2021 18th European Radar Conference (EuRAD), 2022, pp. 437-440.</div>
            <div class="reference">[16] Y. Hu, P. N. Samarasinghe, and T. D. Abhayapala, "Sound source localization using relative harmonic coefficients in modal domain," 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), pp. 348-352, 2019.</div>
            <div class="reference">[19] P. Dwivedi, S. B. Hazare, G. Routray, and R. M. Hegde, "Long-term temporal audio source localization using sh-cmn," 2023 National Conference on Communications (NCC), pp. 1-6, 2023.</div>
            <div class="reference">[31] O. Olgun and H. Hachiabubiqu, "Mettu sparg eigenmike em32 acoustic impulse response dataset v0.1.0," Apr. 2019.</div>
            </section>
            <div class="section">
                <h2>Resources</h2>

                <a href="RHCED_EUSIPCO.pdf" class="btn" target="_blank">📄 Read Full Paper</a>
            </div>
        </div>

        <footer>
            <div class="container">
                <p>&copy; 2024 Politecnico di Milano & Universitat de València. Research funded by MUSA project (European Union) and Spanish MCIN/AEI grants.</p>
                <p>Published at EUSIPCO 2024 Conference</p>
            </div>
        </footer>
    </div>
</body>
</html>