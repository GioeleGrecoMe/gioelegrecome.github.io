<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RHC-ED: Dereverberation via CNNs for Acoustic Source DOA Estimation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Navigation */
        .navigation {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px 0;
            margin-bottom: 20px;
        }

        .nav-home {
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 25px;
            border-radius: 25px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }

        .nav-home:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.2);
        }

        .breadcrumb {
            color: rgba(255, 255, 255, 0.8);
            font-size: 0.9em;
        }

        .breadcrumb a {
            color: rgba(255, 255, 255, 0.9);
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .breadcrumb a:hover {
            color: white;
        }

        header {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(15px);
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
            border-radius: 25px;
            margin: 20px auto;
            padding: 50px;
            text-align: center;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        h1 {
            font-size: 2.8em;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 20px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.3em;
            color: #7f8c8d;
            margin-bottom: 25px;
            font-weight: 300;
        }

        .authors {
            font-size: 1.1em;
            color: #34495e;
            margin-bottom: 15px;
            font-weight: 500;
        }

        .affiliations {
            font-size: 0.95em;
            color: #7f8c8d;
            font-style: italic;
            line-height: 1.5;
        }

        .main-content {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(15px);
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.1);
            border-radius: 25px;
            margin: 20px auto;
            padding: 50px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .section {
            margin-bottom: 50px;
        }

        .section h2 {
            font-size: 2em;
            color: #2c3e50;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 3px solid;
            border-image: linear-gradient(135deg, #667eea, #764ba2) 1;
            display: inline-block;
            font-weight: 600;
        }

        .section h3 {
            font-size: 1.5em;
            color: #34495e;
            margin: 30px 0 20px 0;
            font-weight: 600;
        }

        p {
            margin-bottom: 18px;
            color: #555;
            text-align: justify;
            font-size: 1.05em;
            line-height: 1.7;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.08), rgba(118, 75, 162, 0.08));
            border-left: 5px solid #667eea;
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
            box-shadow: 0 4px 20px rgba(102, 126, 234, 0.1);
        }

        /* Image containers */
        .image-container {
            text-align: center;
            margin: 40px 0;
            padding: 30px;
            background: #f8f9fa;
            border-radius: 20px;
            border: 2px solid #e9ecef;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.05);
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 15px;
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .image-container img:hover {
            transform: scale(1.02);
        }

        .image-caption {
            margin-top: 20px;
            font-style: italic;
            color: #666;
            font-size: 1em;
            line-height: 1.5;
        }

        .architecture-diagram {
            text-align: center;
            margin: 40px 0;
            padding: 30px;
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            border-radius: 20px;
            border: 2px solid #667eea;
            box-shadow: 0 8px 30px rgba(102, 126, 234, 0.1);
        }

        .architecture-diagram h4 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 1.4em;
            font-weight: 600;
        }

        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }

        .result-card {
            background: linear-gradient(135deg, #fff, #f8f9fa);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);
            border: 1px solid #e9ecef;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .result-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.12);
        }

        .result-card h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
            font-weight: 600;
        }

        .metric {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 10px 18px;
            border-radius: 25px;
            display: inline-block;
            margin: 8px 8px 8px 0;
            font-weight: 600;
            font-size: 0.9em;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }

        .code-block {
            background: linear-gradient(135deg, #2c3e50, #34495e);
            color: #ecf0f1;
            padding: 30px;
            border-radius: 15px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            margin: 30px 0;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
            line-height: 1.6;
        }

        .btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 15px 30px;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            text-decoration: none;
            display: inline-block;
            margin: 15px 15px 15px 0;
            font-weight: 600;
            font-size: 1.05em;
            transition: all 0.3s ease;
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.3);
        }

        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 12px 30px rgba(102, 126, 234, 0.4);
        }

        .formula {
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            padding: 25px;
            border-radius: 15px;
            font-family: 'Times New Roman', serif;
            text-align: center;
            margin: 25px 0;
            border: 1px solid #e9ecef;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            font-size: 1.1em;
        }

        .dataset-params {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .param-item {
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            border: 1px solid #e9ecef;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            transition: transform 0.3s ease;
        }

        .param-item:hover {
            transform: translateY(-3px);
        }

        .param-item strong {
            color: #667eea;
            display: block;
            margin-bottom: 8px;
            font-size: 1.1em;
        }

        /* Performance charts placeholders */
        .charts-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .chart-placeholder {
            background: #f8f9fa;
            border: 2px dashed #667eea;
            border-radius: 20px;
            padding: 40px;
            text-align: center;
            min-height: 300px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .chart-placeholder h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .chart-placeholder p {
            color: #666;
            font-style: italic;
        }

        footer {
            text-align: center;
            padding: 40px 0;
            color: rgba(255, 255, 255, 0.9);
            font-size: 0.95em;
            line-height: 1.6;
        }

        ul {
            margin-left: 20px;
            color: #555;
        }

        ul li {
            margin-bottom: 12px;
            line-height: 1.6;
        }

        /* Contribution items styling */
        .contribution-item {
            margin: 20px 0;
            padding: 25px;
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.08), rgba(118, 75, 162, 0.08));
            border-radius: 15px;
            border-left: 5px solid #667eea;
            transition: transform 0.3s ease;
        }

        .contribution-item:hover {
            transform: translateX(5px);
        }

        @media (max-width: 768px) {
            .container {
                padding: 0 15px;
            }

            .navigation {
                flex-direction: column;
                gap: 15px;
                text-align: center;
            }

            header, .main-content {
                margin: 15px auto;
                padding: 30px 20px;
            }

            h1 {
                font-size: 2.2em;
            }

            .results-grid, .charts-container {
                grid-template-columns: 1fr;
            }

            .dataset-params {
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            }

            .chart-placeholder {
                min-height: 250px;
                padding: 30px;
            }
        }

        @media (max-width: 480px) {
            header, .main-content {
                padding: 20px 15px;
            }

            h1 {
                font-size: 1.8em;
            }

            .dataset-params {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Navigation -->
        <div class="navigation">
            <a href="../index.html" class="nav-home">‚Üê Back to Portfolio</a>
            <div class="breadcrumb">
                <a href="../index.html">Home</a> / <a href="#projects">Projects</a> / RHC-ED
            </div>
        </div>

        <header>
            <h1>RHC-ED: Dereverberation of Relative Harmonic Coefficients via CNNs for Acoustic Source DOA Estimation</h1>
            <div class="subtitle">A Deep Learning Approach to Enhance Sound Source Localization in Noisy and Reverberant Environments</div>
            <div class="authors">
                <strong>Gioele Greco¬π, Silvia Messana¬π, Mirco Pezzoli¬π, Maximo Cobos¬≤, Fabio Antonacci¬π</strong>
            </div>
            <div class="affiliations">
                ¬πDipartimento Elettronica Informatica e Bioingegneria, Politecnico di Milano, Italy<br>
                ¬≤Departament d'Inform√†tica, Universitat de Val√®ncia, Spain
            </div>
        </header>

        <div class="main-content">
            <div class="section">
                <h2>Abstract</h2>
                <div class="highlight-box">
                    <p>Relative Harmonic Coefficients (RHCs) are a promising audio descriptor for Direction of Arrival (DOA) estimation but are vulnerable to noise and reverberation. We introduce <strong>RHC-ED</strong>, a convolutional encoder-decoder architecture that processes noisy and reverberant RHCs, restoring their ideal properties by suppressing unwanted artifacts. Using stacked CNNs, RHC-ED compresses and reconstructs RHCs for improved DOA estimation.</p>
                </div>
                <p>Experiments across diverse acoustic conditions confirm RHC-ED's effectiveness in reducing estimation errors and outperforming recent state-of-the-art methods for source localization, especially using first-order spherical harmonics.</p>
            </div>

            <div class="section">
                <h2>Key Contributions</h2>
                <div class="contribution-item">
                    üéØ <strong>Novel Architecture:</strong> Introduction of RHC-ED, a convolutional encoder-decoder specifically designed for RHC dereverberation
                </div>
                <div class="contribution-item">
                    üî¨ <strong>Theoretical Foundation:</strong> Mathematical formulation of RHCs in reverberant environments and their deviation from ideal behavior
                </div>
                <div class="contribution-item">
                    üìä <strong>Comprehensive Evaluation:</strong> Validation on both synthetic datasets and real-world measurements from spherical microphone arrays
                </div>
                <div class="contribution-item">
                    üèÜ <strong>Superior Performance:</strong> Significant improvement over existing methods with 90% confidence intervals of 7¬∞ vs 31¬∞ for competing approaches
                </div>
            </div>

            <div class="section">
                <h2>Spherical Coordinate System</h2>
                <div class="image-container">
                    <img src="spherical_coordinates.png" alt="Spherical Coordinate System" />
                    <div class="image-caption">
                        <strong>Figure 1:</strong> Spherical coordinates system, defined by three components: azimuth œÜ, inclination Œ∏ and radius r. This coordinate system is fundamental for representing sound source positions relative to the spherical microphone array.
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>Methodology</h2>

                <h3>Relative Harmonic Coefficients (RHCs)</h3>
                <p>RHCs are defined as the ratio between spherical harmonic coefficients and the zeroth-order coefficient:</p>
                <div class="formula">
                    Œ≤<sub>nm</sub>(k) = Œ±<sub>nm</sub>(k) / Œ±<sub>00</sub>(k)
                </div>
                <p>In ideal conditions, RHCs depend only on the source Direction of Arrival (DOA), making them particularly valuable for localization algorithms. However, in reverberant environments, this ideal property is compromised.</p>

                <h3>RHC-ED Architecture</h3>
                <div class="image-container">
                    <img src="RH-CED.png" alt="RHC-ED Architecture" />
                    <div class="image-caption">
                        <strong>Figure 2:</strong> RHC-ED architecture description, including kernel dimensions. The encoding and decoding architectures are mirrored, except that the latter uses transposed convolutions instead of standard convolutions to upsample the compressed features.
                    </div>
                </div>

                <div class="architecture-diagram">
                    <h4>Convolutional Encoder-Decoder Architecture</h4>
                    <p><strong>Input:</strong> 6 √ó 256 √ó 10 tensor (Real & Imaginary parts of Œ≤<sub>1,-1</sub>, Œ≤<sub>1,0</sub>, Œ≤<sub>1,1</sub>)</p>
                    <p><strong>Encoder:</strong> 5 Conv layers with progressive dimensionality reduction</p>
                    <p><strong>Decoder:</strong> 5 Transposed Conv layers for reconstruction</p>
                    <p><strong>Output:</strong> Denoised and dereverberated RHCs</p>
                </div>

                <div class="code-block">
Encoder:
- Conv (5√ó3, 64) + ReLU
- Conv (5√ó3, 64) + ReLU
- Conv (5√ó3, 64) + ReLU
- Conv (3√ó3, 128) + ReLU
- Conv (3√ó3, 128) + ReLU

Bottleneck:
- Linear(512) + Dropout(0.3)

Decoder:
- ConvT (3√ó3, 128) + ReLU
- ConvT (3√ó3, 128) + ReLU
- ConvT (5√ó3, 64) + ReLU
- ConvT (5√ó3, 64) + ReLU
- ConvT (5√ó3, 64)
                </div>

                <h3>DOA Estimation</h3>
                <p>The DOA is estimated using the unitary vector derived from first-order RHCs:</p>
                <div class="formula">
                    Œ∑(k) = [sin(œÜ)sin(Œ∏), cos(œÜ)sin(Œ∏), cos(Œ∏)]<sup>T</sup>
                </div>
            </div>

            <div class="section">
                <h2>Dataset & Training</h2>
                <div class="dataset-params">
                    <div class="param-item">
                        <strong>Azimuth (œÜ<sub>s</sub>)</strong>
                        [0¬∞, 360¬∞]
                    </div>
                    <div class="param-item">
                        <strong>Inclination (Œ∏<sub>s</sub>)</strong>
                        [60¬∞, 130¬∞]
                    </div>
                    <div class="param-item">
                        <strong>Distance</strong>
                        [1.5, 3.5]m
                    </div>
                    <div class="param-item">
                        <strong>Room Size</strong>
                        [4-8] √ó [5-10] √ó [3-5]m
                    </div>
                    <div class="param-item">
                        <strong>T‚ÇÜ‚ÇÄ</strong>
                        [0.25, 1.0]s
                    </div>
                    <div class="param-item">
                        <strong>SNR</strong>
                        [5, 60]dB
                    </div>
                </div>
                <p>The dataset consists of synthetic RIRs generated using the SMIR generator with Eigenmike 32-channel spherical microphone array configurations. Speech signals from LibriSpeech were convolved with RIRs to create realistic acoustic scenarios with varying reverberation times and noise levels.</p>
            </div>

            <div class="section">
                <h2>Results</h2>

                <h3>Performance Analysis</h3>
                <div class="charts-container">
                    <div class="chart-placeholder">
                        <img src="AE_vs_T60.png" alt="Synthetic Dataset Results" style="max-width: 100%; height: auto; border: none; box-shadow: none;" />
                        <div class="image-caption">
                            <strong>Figure 3:</strong> AE distribution derived from 50 audio samples from the test set for each T‚ÇÜ‚ÇÄ with SNR in the whole considered range. Solid lines indicate the mean value across all 50 samples, while shaded regions represent the standard deviation.
                        </div>
                    </div>

                    <div class="chart-placeholder">
                        <img src="AE_histogram.png" alt="Real-world Dataset Results" style="max-width: 100%; height: auto; border: none; box-shadow: none;" />
                        <div class="image-caption">
                            <strong>Figure 4:</strong> Probability density function of the AE distribution obtained from real-world measurements. Bars indicate the probability of AE for each 2¬∞ sector, dashed lines indicate the 90% confidence interval.
                        </div>
                    </div>
                </div>

                <div class="results-grid">
                    <div class="result-card">
                        <h4>Synthetic Dataset Performance</h4>
                        <p>Evaluated on 50 samples across different T‚ÇÜ‚ÇÄ values (0.25-1.0s)</p>
                        <div class="metric">Consistently Superior Accuracy</div>
                        <div class="metric">Robust to Reverberation</div>
                        <p>RHC-ED consistently outperformed both unprocessed RHCs and existing classification-based methods across all reverberation conditions.</p>
                    </div>
                    <div class="result-card">
                        <h4>Real-World Validation</h4>
                        <p>Tested on real measurements from METU SPARG Eigenmike dataset</p>
                        <div class="metric">RHC-ED: 7¬∞ (90% CI)</div>
                        <div class="metric">Measured RHCs: 14¬∞ (90% CI)</div>
                        <div class="metric">Dwivedi et al.: 31¬∞ (90% CI)</div>
                        <p>RHC-ED achieved the lowest angular error with significantly tighter confidence intervals.</p>
                    </div>
                </div>

                <div class="highlight-box">
                    <h3>Key Performance Metrics</h3>
                    <p><strong>Angular Error (AE):</strong> AE(Œ∑) = |arccos(‚àë·¥∏‚Çó‚Çå‚ÇÅ Œ∑(k‚Çó)·µÄ/L ¬∑ Œ∑_GT)|¬∞</p>
                    <p><strong>Standard Deviation:</strong> Measured across T = 418 time frame estimates per sample</p>
                    <p><strong>Confidence Intervals:</strong> RHC-ED shows 50% reduction in error compared to unprocessed RHCs and 77% reduction compared to competing methods</p>
                </div>
            </div>

            <div class="section">
                <h2>Technical Implementation</h2>
                <h3>Input Features</h3>
                <p>The input consists of time-frequency representations of RHCs limited to order N=1, with each coefficient decomposed into real and imaginary components. The system processes 10 consecutive time frames with 256 frequency bins.</p>

                <h3>Training Strategy</h3>
                <p>The model was trained using Mean Square Error (MSE) loss to minimize the difference between processed RHCs and their ideal anechoic counterparts. A voice activity detector was implemented to discard inactive source frames during evaluation.</p>

                <h3>Advantages over Classification Approaches</h3>
                <ul>
                    <li>Continuous DOA estimation vs. discrete 5¬∞ intervals</li>
                    <li>Direct processing of acoustic features rather than classification</li>
                    <li>Better handling of first-order spherical harmonics</li>
                    <li>Superior performance in reverberant conditions</li>
                </ul>
            </div>

            <div class="section">
                <h2>Future Directions</h2>
                <p>The RHC-ED framework opens several avenues for future research:</p>
                <ul>
                    <li><strong>Higher-Order Extensions:</strong> Extending to higher-order spherical harmonics for improved spatial resolution</li>
                    <li><strong>Multi-Source Scenarios:</strong> Adapting the architecture for simultaneous localization of multiple sources</li>
                    <li><strong>Real-Time Implementation:</strong> Optimizing the network for real-time processing applications</li>
                    <li><strong>Transfer Learning:</strong> Investigating domain adaptation for different acoustic environments</li>
                </ul>
            </div>
            <section id="references">
            <h2>References</h2>
            <div class="reference">[1] M. Cobos, F. Antonacci, A. Alexandridis, A. Moucharis, and B. Lee, "A survey of sound source localization methods in wireless acoustic sensor networks," Wireless Communications and Mobile Computing, vol. 2017, no. 1, p. 3956282, 2017.</div>
            <div class="reference">[2] W. Shi, J. Huang, and Y. Hou, "Fast doa estimation algorithm for mimo sonar based on ant colony optimization," Journal of Systems Engineering and Electronics, vol. 23, no. 2, pp. 173-178, 2021.</div>
            <div class="reference">[3] Y. Wu, C. Li, Y. T. Hou, and W. Lou, "Real-time doa estimation for automotive radar," in 2021 18th European Radar Conference (EuRAD), 2022, pp. 437-440.</div>
            <div class="reference">[16] Y. Hu, P. N. Samarasinghe, and T. D. Abhayapala, "Sound source localization using relative harmonic coefficients in modal domain," 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), pp. 348-352, 2019.</div>
            <div class="reference">[19] P. Dwivedi, S. B. Hazare, G. Routray, and R. M. Hegde, "Long-term temporal audio source localization using sh-cmn," 2023 National Conference on Communications (NCC), pp. 1-6, 2023.</div>
            <div class="reference">[31] O. Olgun and H. Hachiabubiqu, "Mettu sparg eigenmike em32 acoustic impulse response dataset v0.1.0," Apr. 2019.</div>
            </section>
            <div class="section">
                <h2>Resources</h2>

                <a href="RHCED_EUSIPCO.pdf" class="btn" target="_blank">üìÑ Read Full Paper</a>
            </div>
        </div>

        <footer>
            <div class="container">
                <p>&copy; 2024 Politecnico di Milano & Universitat de Val√®ncia. Research funded by MUSA project (European Union) and Spanish MCIN/AEI grants.</p>
                <p>Published at EUSIPCO 2024 Conference</p>
            </div>
        </footer>
    </div>
</body>
</html>