<!doctype html>
<html lang="it">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Fruit Ripeness — IR Measurement Tool (Fixed)</title>
  <style>
    :root {
      --bg: #0b1220;
      --card: #0f1724;
      --accent: #60a5fa;
      --muted: #94a3b8;
      --success: #34d399;
      --warn: #f59e0b;
      --danger: #ef4444;
      --glass: rgba(255, 255, 255, 0.02);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      min-height: 100vh;
      font-family: system-ui, -apple-system, 'Segoe UI', Roboto, Arial;
      color: #e6eef8;
      background: linear-gradient(180deg, #071029 0%, #071827 100%);
    }
    nav#navbar{
      max-width: 1100px;
      margin: 14px auto 0;
      padding: 0 20px;
      display:flex;
      align-items:center;
      justify-content:space-between;
      gap: 12px;
    }
    .logo { color: #fff; text-decoration: none; font-size: 1.1rem; font-weight: 700; }
    .logo span { font-weight: 400; font-size: 0.9rem; opacity: 0.85; margin-left: 6px; }
    .nav-links { display: flex; list-style: none; padding:0; margin:0; gap: 14px; }
    .nav-links a { color:#fff; text-decoration:none; opacity:0.9; }
    .nav-links a:hover{ color: var(--accent); opacity: 1; }

    .app {
      max-width: 1100px;
      margin: 14px auto 28px;
      padding: 20px;
      background: linear-gradient(180deg, rgba(255, 255, 255, 0.02), transparent);
      border-radius: 12px;
      box-shadow: 0 6px 30px rgba(2, 6, 23, 0.6);
    }
    .app-header { display: flex; align-items: center; justify-content: space-between; margin-bottom: 8px; gap: 10px; }
    .app-header h1 { margin: 0; font-size: 20px; }
    .pill {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.08);
      background: rgba(255,255,255,0.03);
      color: var(--muted);
      font-size: 12px;
      user-select: none;
    }
    button {
      font-weight: 700;
      border-radius: 10px;
      padding: 10px 14px;
      border: none;
      cursor: pointer;
      background: rgba(255,255,255,0.06);
      color: #e6eef8;
    }
    button.primary { background: var(--accent); color: #04202e; }
    button.ghost { background: transparent; color: var(--muted); border: 1px solid rgba(255,255,255,0.10); padding: 8px 10px; }
    button:disabled { opacity: 0.45; cursor: not-allowed; }

    .stage { padding: 12px 0; }
    .hidden { display: none !important; }

    .device-grid { display: grid; grid-template-columns:1fr; gap: 12px; margin-bottom: 12px; }
    @media (min-width: 700px) { .device-grid { grid-template-columns: 1fr 1fr; } }

    .control { display:flex; flex-direction: column; gap: 6px; margin-bottom: 8px; }
    .control label { font-size: 13px; color: var(--muted); }
    .control input[type=number], .control select, .control input[type=range] {
      padding: 10px;
      border-radius: 10px;
      border: 1px solid rgba(255, 255, 255, 0.08);
      background: var(--glass);
      color: inherit;
      outline: none;
    }
    .params { display: grid; grid-template-columns: repeat(2, 1fr); gap: 12px; margin: 12px 0; }
    @media (min-width: 980px){ .params { grid-template-columns: repeat(4, 1fr); } }

    .row.actions { display:flex; flex-wrap: wrap; gap: 10px; margin-top: 10px; align-items:center; }
    .hint { color: var(--muted); margin-top: 10px; line-height: 1.35; }
    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace; }

    .plots { display:flex; gap: 12px; flex-wrap: wrap; margin-top: 12px; }
    .plots canvas { width: 100%; max-width: 600px; background: #020617; border-radius: 10px; padding: 8px; }

    .loader { display:none; align-items:center; gap: 12px; margin-top: 12px; }
    .loader.show { display:flex; }
    .pulse { width: 32px; height: 32px; border-radius: 999px; background: linear-gradient(180deg, var(--accent), #34d399); box-shadow: 0 8px 30px rgba(96, 165, 250, 0.12); animation: pulse 1.2s infinite; }
    @keyframes pulse { 0% { transform: scale(1); opacity: 1; } 50% { transform: scale(1.12); opacity: 0.9; } 100% { transform: scale(1); opacity: 1; } }
    .loader-text { font-weight: 800; color: var(--muted); }

    .json-preview { background: #021024; padding: 12px; border-radius: 10px; color: #a6b8d9; max-height: 280px; overflow: auto; margin-top: 12px; }
    .app-footer { margin-top: 16px; color: var(--muted); font-size: 13px; }

    .test-block { margin: 10px 0; padding: 12px; border: 1px solid rgba(255, 255, 255, 0.08); border-radius: 12px; background: rgba(255, 255, 255, 0.02) }
    .test-head { display:flex; gap: 10px; align-items:center; justify-content: space-between; margin-bottom: 8px; }
    .muted { color: var(--muted); font-size: 13px; }
    .warn { color: var(--warn); }
    .danger { color: var(--danger); }
    .ok { color: var(--success); }

    #micScope { width: 100%; height: 140px; background: #020617; border-radius: 10px; }
    .kv { display:flex; flex-wrap: wrap; gap: 10px; margin-top: 8px; }
  </style>
</head>

<body>
<nav id="navbar">
  <a href="../index.html" class="logo">Acoustic Research<span>Innovative Sound Solutions</span></a>
  <ul class="nav-links">
    <li><a href="../index.html#about">About</a></li>
    <li><a href="../index.html#projects">Projects</a></li>
    <li><a href="../index.html#contact">Contact</a></li>
  </ul>
</nav>

<main class="app">
  <header class="app-header">
    <div>
      <h1>Fruit Ripeness — IR Measurement Tool</h1>
      <div class="kv">
        <span id="compatPill" class="pill">Compatibilità: in verifica…</span>
        <span id="httpsPill" class="pill">Sicurezza: in verifica…</span>
      </div>
    </div>
    <button id="backBtn" class="ghost" title="Back">← Back</button>
  </header>

  <!-- Stage 0: Device Setup -->
  <section id="stage-0" class="stage">
    <h2>Stage 0 — Setup & Test</h2>

    <p id="permStatus">In attesa dei permessi microfono.</p>

    <div class="device-grid">
      <div class="control">
        <label for="inputSelect">Microfono (input)</label>
        <select id="inputSelect"></select>
        <div class="muted">Suggerimento: scegli il microfono “inferiore” per i telefoni (di solito vicino al bordo).</div>
      </div>

      <div class="control">
        <label for="outputSelect">Uscita audio (speaker)</label>
        <select id="outputSelect"></select>
        <div id="outputNote" class="muted"></div>
      </div>
    </div>

    <div class="params">
      <div class="control">
        <label for="delay">Delay prima dello sweep (s)</label>
        <input id="delay" type="number" min="0" step="0.1" value="0.8">
      </div>
      <div class="control">
        <label for="sweepDuration">Durata sweep (s)</label>
        <input id="sweepDuration" type="number" min="0.5" step="0.1" value="3.5">
      </div>
      <div class="control">
        <label for="f1">Freq inizio (Hz)</label>
        <input id="f1" type="number" min="10" value="80">
      </div>
      <div class="control">
        <label for="f2">Freq fine (Hz)</label>
        <input id="f2" type="number" min="200" value="9000">
      </div>
      <div class="control">
        <label for="outputGain">Volume sweep (0–100%)</label>
        <input id="outputGain" type="range" min="5" max="100" step="1" value="45">
      </div>
      <div class="control">
        <label for="tailSilence">Coda post-sweep (s)</label>
        <input id="tailSilence" type="number" min="0" step="0.05" value="0.35">
      </div>
    </div>

    <div class="row actions">
      <button id="requestPermBtn">Concedi permesso microfono</button>
      <button id="startAppBtn" class="primary" disabled>Inizia →</button>
    </div>

    <!-- Mic realtime test -->
    <div id="micTest" class="test-block hidden">
      <div class="test-head">
        <strong>Test microfono (waveform)</strong>
        <span class="muted">Batti vicino al mic e guarda l’onda.</span>
      </div>
      <canvas id="micScope" width="900" height="140"></canvas>
      <div class="row actions">
        <button id="stopMicTestBtn" class="ghost">Stop monitor</button>
      </div>
    </div>

    <!-- Speaker test -->
    <div id="speakerTest" class="test-block">
      <div class="test-head">
        <strong>Test speaker</strong>
        <span class="muted">Riproduce un beep breve.</span>
      </div>
      <div class="row actions">
        <button id="playTestSoundBtn" class="primary">Play test sound</button>
      </div>
    </div>

    <div class="test-block">
      <div class="test-head">
        <strong>Note importanti</strong>
        <span class="muted">Per risultati più affidabili</span>
      </div>
      <ul class="muted" style="margin:0; padding-left: 18px; line-height:1.35;">
        <li><b>HTTPS obbligatorio</b> (o <span class="mono">localhost</span>) per usare microfono su molti browser.</li>
        <li>Su iOS/Safari non è possibile scegliere il “sink” (uscita): l’app usa l’uscita di sistema.</li>
        <li>Riduci il volume se vedi “clipping” o distorsioni. Fai 2–4 run e usa la media/mediana.</li>
      </ul>
    </div>
  </section>

  <!-- Stage 1: Calibration -->
  <section id="stage-1" class="stage hidden">
    <h2>Stage 1 — Calibrazione (mano)</h2>
    <p>Appoggia microfono e speaker sulla mano e premi <b>Avvia calibrazione</b>. Ripeti 2–4 volte: la media migliora il rapporto segnale/rumore.</p>

    <div class="row actions">
      <button id="startCalBtn" class="primary">Avvia calibrazione</button>
      <button id="addCalRunBtn" class="ghost" disabled>Aggiungi run</button>
      <button id="resetCalRunsBtn" class="ghost">Reset</button>
      <span id="calRunCount" class="muted">0 run</span>
      <span id="calQuality" class="muted"></span>
    </div>

    <div id="calLoader" class="loader">
      <div class="pulse"></div>
      <div class="loader-text">Misurazione…</div>
    </div>

    <div id="calPlots" class="plots hidden">
      <canvas id="calRaw" width="600" height="170"></canvas>
      <canvas id="calIRTime" width="600" height="170"></canvas>
      <canvas id="calIRFreq" width="600" height="170"></canvas>
    </div>

    <div class="row actions">
      <button id="continueToMeasureBtn" class="primary" disabled>Continua →</button>
    </div>
  </section>

  <!-- Stage 2: Fruit Measurement -->
  <section id="stage-2" class="stage hidden">
    <h2>Stage 2 — Misura (frutto)</h2>
    <p>Appoggia microfono e speaker sul frutto e premi <b>Avvia misura</b>. Ripeti e fai media.</p>

    <div class="row actions">
      <button id="startMeasBtn" class="primary">Avvia misura</button>
      <button id="addMeasRunBtn" class="ghost" disabled>Aggiungi run</button>
      <button id="resetMeasRunsBtn" class="ghost">Reset</button>
      <span id="measRunCount" class="muted">0 run</span>
      <span id="measQuality" class="muted"></span>
    </div>

    <div id="measLoader" class="loader">
      <div class="pulse"></div>
      <div class="loader-text">Misurazione…</div>
    </div>

    <div id="measPlots" class="plots hidden">
      <canvas id="measRaw" width="600" height="170"></canvas>
      <canvas id="measIRTime" width="600" height="170"></canvas>
      <canvas id="measIRFreq" width="600" height="170"></canvas>
    </div>

    <div class="row actions">
      <button id="continueToCompareBtn" class="primary" disabled>Continua →</button>
    </div>
  </section>

  <!-- Stage 3: Comparison & Download -->
  <section id="stage-3" class="stage hidden">
    <h2>Stage 3 — Confronto & Download</h2>
    <p>Confronto tra risposte medie di calibrazione e frutto. Etichetta la maturazione e scarica i dati.</p>

    <div class="control" style="margin-top: 10px;">
      <label for="ripeness">Maturazione (0–10): <span id="ripenessVal">5</span></label>
      <input id="ripeness" type="range" min="0" max="10" step="1" value="5">
    </div>

    <div id="comparePlots" class="plots">
      <canvas id="cmpIR" width="600" height="190"></canvas>
      <canvas id="cmpFR" width="600" height="190"></canvas>
    </div>

    <div class="row actions">
      <button id="downloadJsonBtn" class="primary">Download JSON</button>
      <button id="downloadCsvBtn" class="ghost">Download CSV (feature)</button>
    </div>

    <pre id="jsonPreview" class="json-preview"></pre>
  </section>

  <footer class="app-footer">
    Built with Web Audio API • Demo educativo • <span class="mono">v1.1-fixed</span>
  </footer>
</main>

<script>
/*
  Fruit Ripeness — IR Measurement Tool (Fixed & Hardened)

  Obiettivi di questa revisione:
  - Rendere l'app "realmente funzionante" su più browser/dispositivi possibili (con i limiti del Web).
  - Fix bug bloccanti (ChannelSplitter API errata, FFT errata, averaging su array di lunghezze diverse -> NaN).
  - Aumentare robustezza:
      - lunghezza buffer uniforme (troncamento/zero-pad) -> si può fare media tra run
      - inverse sweep corretto (Farina-style) per log sweep
      - riduzione feedback: ScriptProcessor con "gain=0" invece che diretto a destination
      - indicatori qualità (clipping + SNR semplice)
      - compatibilità: output “default” sempre disponibile (molti device non espongono audiooutput)
  - Aggiungere commenti di debug utili.

  NOTE IMPORTANTI:
  - getUserMedia richiede HTTPS (o localhost). Su file:// può fallire.
  - Se setSinkId non è supportato (es. iOS), la selezione output non può forzare lo speaker.
  - Le misure acustiche via microfono+speaker in aria sono rumorose: per “risultati affidabili”
    bisogna usare features relative (calibrazione), run multiple e metriche robuste.
*/

'use strict';

// -------------------------------
// UI refs
// -------------------------------
const stages = {
  0: document.getElementById('stage-0'),
  1: document.getElementById('stage-1'),
  2: document.getElementById('stage-2'),
  3: document.getElementById('stage-3')
};
const backBtn = document.getElementById('backBtn');

const permStatus = document.getElementById('permStatus');
const compatPill = document.getElementById('compatPill');
const httpsPill  = document.getElementById('httpsPill');

const requestPermBtn = document.getElementById('requestPermBtn');
const startAppBtn = document.getElementById('startAppBtn');

const inputSelect = document.getElementById('inputSelect');
const outputSelect = document.getElementById('outputSelect');
const outputNote = document.getElementById('outputNote');

const delayEl = document.getElementById('delay');
const sweepDurationEl = document.getElementById('sweepDuration');
const f1El = document.getElementById('f1');
const f2El = document.getElementById('f2');
const outputGainEl = document.getElementById('outputGain');
const tailSilenceEl = document.getElementById('tailSilence');

const micTest = document.getElementById('micTest');
const micScope = document.getElementById('micScope');
const stopMicTestBtn = document.getElementById('stopMicTestBtn');

const speakerTest = document.getElementById('speakerTest');
const playTestSoundBtn = document.getElementById('playTestSoundBtn');

// Stage 1
const startCalBtn = document.getElementById('startCalBtn');
const addCalRunBtn = document.getElementById('addCalRunBtn');
const resetCalRunsBtn = document.getElementById('resetCalRunsBtn');
const calRunCount = document.getElementById('calRunCount');
const calQuality = document.getElementById('calQuality');
const calLoader = document.getElementById('calLoader');
const calPlots = document.getElementById('calPlots');
const calRawCanvas = document.getElementById('calRaw');
const calIRTimeCanvas = document.getElementById('calIRTime');
const calIRFreqCanvas = document.getElementById('calIRFreq');
const continueToMeasureBtn = document.getElementById('continueToMeasureBtn');

// Stage 2
const startMeasBtn = document.getElementById('startMeasBtn');
const addMeasRunBtn = document.getElementById('addMeasRunBtn');
const resetMeasRunsBtn = document.getElementById('resetMeasRunsBtn');
const measRunCount = document.getElementById('measRunCount');
const measQuality = document.getElementById('measQuality');
const measLoader = document.getElementById('measLoader');
const measPlots = document.getElementById('measPlots');
const measRawCanvas = document.getElementById('measRaw');
const measIRTimeCanvas = document.getElementById('measIRTime');
const measIRFreqCanvas = document.getElementById('measIRFreq');
const continueToCompareBtn = document.getElementById('continueToCompareBtn');

// Stage 3
const ripenessSlider = document.getElementById('ripeness');
const ripenessVal = document.getElementById('ripenessVal');
const cmpIR = document.getElementById('cmpIR');
const cmpFR = document.getElementById('cmpFR');
const downloadJsonBtn = document.getElementById('downloadJsonBtn');
const downloadCsvBtn = document.getElementById('downloadCsvBtn');
const jsonPreview = document.getElementById('jsonPreview');

// -------------------------------
// Stage navigation
// -------------------------------
function showStage(n) {
  Object.values(stages).forEach(s => s.classList.add('hidden'));
  stages[n].classList.remove('hidden');
  backBtn.style.display = (n === 0) ? 'none' : 'inline-block';
}
showStage(0);

// -------------------------------
// Audio state
// -------------------------------
let audioContext = null;

// Streams for recording and monitoring (kept separate to avoid interfering each other)
let currentStream = null;
let monitorStream = null;

// Monitor nodes
let monitorSource = null;
let monitorAnalyser = null;
let monitorRAF = 0;

// Saved runs (each run has uniform-length arrays)
let calRuns = [];   // [{ raw, rir, freq, meta }]
let measRuns = [];

// Constants that improve repeatability across runs
const IR_WINDOW_SEC = 0.50;   // how much IR we keep around the peak for averaging/features
const IR_PRE_SEC    = 0.020;  // keep some samples before peak (for noise estimate)
const MAX_EXPORT_SAMPLES = 50000; // export guard (avoid huge JSON on long recordings)

// -------------------------------
// Compatibility checks / pills
// -------------------------------
function setPill(el, text, cls) {
  el.textContent = text;
  el.classList.remove('ok','warn','danger');
  if (cls) el.classList.add(cls);
}

function updateCompatibilityPills() {
  const hasMedia = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
  const hasAC = !!(window.AudioContext || window.webkitAudioContext);
  const hasMR = typeof window.MediaRecorder !== 'undefined';
  const hasSink = (typeof HTMLMediaElement !== 'undefined') && (typeof HTMLMediaElement.prototype.setSinkId === 'function');

  // Compat summary: green if WebAudio + getUserMedia exist, amber otherwise.
  if (hasMedia && hasAC) setPill(compatPill, 'Compatibilità: OK (WebAudio + Mic)', 'ok');
  else setPill(compatPill, 'Compatibilità: limitata (manca WebAudio o Mic)', 'danger');

  // HTTPS summary
  const isSecure = (location.protocol === 'https:' || location.hostname === 'localhost' || location.hostname === '127.0.0.1');
  if (isSecure) setPill(httpsPill, 'Sicurezza: OK (HTTPS/localhost)', 'ok');
  else setPill(httpsPill, 'Sicurezza: serve HTTPS (mic può fallire)', 'warn');

  // Output device note
  outputNote.textContent = hasSink
    ? 'Questo browser permette di scegliere l’uscita (setSinkId).'
    : 'Questo browser NON permette di forzare l’uscita (setSinkId assente): userà lo speaker di sistema.';

  // Debug-friendly info in console
  console.log('[compat]', { hasMedia, hasAC, hasMR, hasSink, isSecure });
}
updateCompatibilityPills();

// -------------------------------
// Helpers
// -------------------------------
function ensureAudioContext() {
  if (!audioContext) {
    const Ctx = window.AudioContext || window.webkitAudioContext;
    audioContext = new Ctx();
    console.log('[audio] created AudioContext @', audioContext.sampleRate, 'Hz');
  }
  return audioContext;
}

async function resumeAudioIfNeeded() {
  const ctx = ensureAudioContext();
  if (ctx.state === 'suspended') {
    await ctx.resume();
    console.log('[audio] resumed');
  }
}

function clearCanvas(canvas) {
  const ctx = canvas.getContext('2d');
  ctx.clearRect(0, 0, canvas.width, canvas.height);
}

function clamp(x, a, b){ return Math.max(a, Math.min(b, x)); }

function resizeToLength(arr, len) {
  // Ensures arrays used for averaging have identical lengths.
  // If arr is shorter -> zero-pad. If longer -> truncate.
  const out = new Float32Array(len);
  if (!arr || !arr.length) return out;
  out.set(arr.subarray(0, Math.min(len, arr.length)));
  return out;
}

function safeMinLen(arrays) {
  let m = Infinity;
  for (const a of arrays) m = Math.min(m, a.length);
  return (m === Infinity) ? 0 : m;
}

function averageFloatArrays(arrays) {
  // Robust mean: average on the minimum shared length.
  const len = safeMinLen(arrays);
  const out = new Float32Array(len);
  if (!len) return out;
  for (const a of arrays) {
    for (let i = 0; i < len; i++) out[i] += a[i];
  }
  for (let i = 0; i < len; i++) out[i] /= arrays.length;
  return out;
}

function medianFloatArrays(arrays) {
  // Optional: robust aggregation. We keep mean for visuals, but this is available.
  const len = safeMinLen(arrays);
  const out = new Float32Array(len);
  if (!len) return out;
  const tmp = new Array(arrays.length);
  for (let i = 0; i < len; i++) {
    for (let r = 0; r < arrays.length; r++) tmp[r] = arrays[r][i];
    tmp.sort((a,b)=>a-b);
    out[i] = tmp[Math.floor(tmp.length/2)];
  }
  return out;
}

function updateRunCounters() {
  calRunCount.textContent = `${calRuns.length} run`;
  measRunCount.textContent = `${measRuns.length} run`;
}

// -------------------------------
// Device enumeration / permissions
// -------------------------------
function updateStartEnabled() {
  // Output selection is optional (many devices don't expose sinks).
  startAppBtn.disabled = !inputSelect.value;
}

async function enumerateDevices() {
  if (!navigator.mediaDevices?.enumerateDevices) {
    permStatus.textContent = 'enumerateDevices non disponibile.';
    return;
  }
  try {
    const devices = await navigator.mediaDevices.enumerateDevices();
    const inputs = devices.filter(d => d.kind === 'audioinput');
    const outputs = devices.filter(d => d.kind === 'audiooutput');

    // --- Inputs ---
    inputSelect.innerHTML = '';
    if (!inputs.length) {
      // Provide a default option anyway: getUserMedia can still pick default device.
      const o = document.createElement('option');
      o.value = 'default';
      o.textContent = 'Default microphone';
      inputSelect.appendChild(o);
    } else {
      inputs.forEach((d, i) => {
        // Device labels are available only after permission on many browsers.
        const label = d.label || `Microphone ${i + 1}`;

        // Stereo splitting heuristic: we keep it BUT we never call invalid APIs.
        // We store a "virtual" id with suffix for later channel select.
        const lower = label.toLowerCase();
        const looksStereo = (lower.includes('stereo') || lower.includes('2-') || lower.includes('2 ch') || lower.includes('2ch'));
        if (looksStereo) {
          const oL = document.createElement('option');
          oL.value = `${d.deviceId}__left`;
          oL.textContent = `${label} (Left)`;
          inputSelect.appendChild(oL);

          const oR = document.createElement('option');
          oR.value = `${d.deviceId}__right`;
          oR.textContent = `${label} (Right)`;
          inputSelect.appendChild(oR);
        } else {
          const o = document.createElement('option');
          o.value = d.deviceId;
          o.textContent = label;
          inputSelect.appendChild(o);
        }
      });
    }

    // --- Outputs ---
    outputSelect.innerHTML = '';
    // Always include a safe "default" output.
    const def = document.createElement('option');
    def.value = 'default';
    def.textContent = 'Uscita di sistema (default)';
    outputSelect.appendChild(def);

    outputs.forEach((d, i) => {
      const o = document.createElement('option');
      o.value = d.deviceId;
      o.textContent = d.label || `Speaker ${i + 1}`;
      outputSelect.appendChild(o);
    });

    permStatus.textContent = inputs.length
      ? 'Microfono pronto. Seleziona input e fai i test.'
      : 'Nessun microfono enumerato (proverò con default).';

    // Start mic monitor automatically after device selection.
    updateStartEnabled();
  } catch (e) {
    console.warn('[enumerateDevices] error', e);
    permStatus.textContent = 'Impossibile enumerare dispositivi (vedi console).';
  }
}

async function requestPermissions() {
  try {
    permStatus.textContent = 'Richiesta permesso microfono…';
    await resumeAudioIfNeeded();

    // Ask for audio only; no special constraints (device selection later).
    const s = await navigator.mediaDevices.getUserMedia({ audio: true });
    // Immediately stop: we only needed permission unlock + labels.
    s.getTracks().forEach(t => t.stop());

    permStatus.textContent = 'Permesso microfono concesso.';
    await enumerateDevices();
  } catch (e) {
    console.warn('[permissions] denied', e);
    permStatus.innerHTML = '<span class="danger">Permesso microfono negato.</span> (Controlla impostazioni browser/OS)';
  }
}

// Use ondevicechange when available (safest cross-browser)
if (navigator.mediaDevices) {
  navigator.mediaDevices.ondevicechange = () => enumerateDevices();
}

// -------------------------------
// Realtime mic monitor (fix ChannelSplitter usage)
// -------------------------------
async function startMicMonitor(virtualDeviceId) {
  await stopMicMonitor();
  await resumeAudioIfNeeded();

  try {
    const { deviceId, channel } = parseVirtualDeviceId(virtualDeviceId);

    monitorStream = await navigator.mediaDevices.getUserMedia({
      audio: { deviceId: deviceId ? { exact: deviceId } : undefined }
    });

    monitorSource = audioContext.createMediaStreamSource(monitorStream);

    // Analyzer
    monitorAnalyser = audioContext.createAnalyser();
    monitorAnalyser.fftSize = 2048;

    // If user selected a virtual L/R channel, split and connect only that channel.
    // IMPORTANT: ChannelSplitterNode does NOT have ".get()" (that was a bug in the original code).
    if (channel !== null) {
      const splitter = audioContext.createChannelSplitter(2);
      const tap = audioContext.createGain();
      tap.gain.value = 1.0;

      monitorSource.connect(splitter);

      // If device is mono but user selected Right, we still connect Left (fallback).
      const chIndex = (channel === 1) ? 1 : 0;
      splitter.connect(tap, chIndex);
      tap.connect(monitorAnalyser);
    } else {
      monitorSource.connect(monitorAnalyser);
    }

    micTest.classList.remove('hidden');

    const ctx = micScope.getContext('2d');
    const N = monitorAnalyser.fftSize;
    const data = new Uint8Array(N);

    function draw() {
      monitorRAF = requestAnimationFrame(draw);
      monitorAnalyser.getByteTimeDomainData(data);
      const w = micScope.width, h = micScope.height;

      ctx.clearRect(0, 0, w, h);
      ctx.fillStyle = '#071022';
      ctx.fillRect(0, 0, w, h);

      ctx.strokeStyle = '#34d399';
      ctx.lineWidth = 2;
      ctx.beginPath();
      const slice = w / N;
      let x = 0;
      for (let i = 0; i < N; i++) {
        const v = (data[i] - 128) / 128;  // [-1..1]
        const y = (0.5 - v * 0.4) * h;
        if (i) ctx.lineTo(x, y); else ctx.moveTo(x, y);
        x += slice;
      }
      ctx.stroke();
    }
    draw();
  } catch (e) {
    console.warn('[micMonitor] error', e);
    alert('Impossibile avviare monitor microfono: ' + (e.message || e));
  }
}

async function stopMicMonitor() {
  if (monitorRAF) { cancelAnimationFrame(monitorRAF); monitorRAF = 0; }
  if (monitorSource) { try { monitorSource.disconnect(); } catch {} monitorSource = null; }
  if (monitorAnalyser) { try { monitorAnalyser.disconnect(); } catch {} monitorAnalyser = null; }
  if (monitorStream) { monitorStream.getTracks().forEach(t => t.stop()); monitorStream = null; }
}

function parseVirtualDeviceId(virtualId) {
  // We used "__left" and "__right" suffixes. Keep it explicit and debuggable.
  // Returns { deviceId, channel } where channel is 0/1 or null.
  if (!virtualId || virtualId === 'default') return { deviceId: null, channel: null };
  if (virtualId.includes('__left'))  return { deviceId: virtualId.replace('__left',''),  channel: 0 };
  if (virtualId.includes('__right')) return { deviceId: virtualId.replace('__right',''), channel: 1 };
  return { deviceId: virtualId, channel: null };
}

// -------------------------------
// Speaker test (setSinkId when available; fallback oscillator)
// -------------------------------
function floatToWav(float32Array, sampleRate) {
  // Minimal WAV encoder (mono 16-bit PCM)
  const numChannels = 1, bps = 2, block = numChannels * bps, dataSize = float32Array.length * bps;
  const buffer = new ArrayBuffer(44 + dataSize);
  const v = new DataView(buffer);

  function wstr(off, s) { for (let i = 0; i < s.length; i++) v.setUint8(off + i, s.charCodeAt(i)); }

  wstr(0, 'RIFF');
  v.setUint32(4, 36 + dataSize, true);
  wstr(8, 'WAVE');
  wstr(12, 'fmt ');
  v.setUint32(16, 16, true);
  v.setUint16(20, 1, true);
  v.setUint16(22, numChannels, true);
  v.setUint32(24, sampleRate, true);
  v.setUint32(28, sampleRate * block, true);
  v.setUint16(32, block, true);
  v.setUint16(34, bps * 8, true);
  wstr(36, 'data');
  v.setUint32(40, dataSize, true);

  let off = 44;
  for (let i = 0; i < float32Array.length; i++, off += 2) {
    let s = clamp(float32Array[i], -1, 1);
    v.setInt16(off, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
  }
  return new Blob([v], { type: 'audio/wav' });
}

function generateBeepFloat(sr = 48000, dur = 0.35, f = 1200) {
  const len = Math.floor(sr * dur);
  const a = new Float32Array(len);

  // Gentle fade to avoid click
  const fade = Math.floor(sr * 0.01);
  for (let n = 0; n < len; n++) {
    let amp = 0.7;
    if (n < fade) amp *= n / fade;
    if (n > len - fade) amp *= (len - n) / fade;
    a[n] = amp * Math.sin(2 * Math.PI * f * (n / sr));
  }
  return { arr: a, sr };
}

async function playTestBeepForSink(sinkId) {
  await resumeAudioIfNeeded();

  // Use setSinkId only if supported AND sinkId is not default.
  const canSink = (typeof HTMLMediaElement !== 'undefined') && (typeof HTMLMediaElement.prototype.setSinkId === 'function');
  if (canSink && sinkId && sinkId !== 'default') {
    try {
      const { arr, sr } = generateBeepFloat();
      const url = URL.createObjectURL(floatToWav(arr, sr));
      const el = new Audio();
      await el.setSinkId(sinkId);
      el.src = url;
      await el.play();
      await new Promise(r => { el.onended = r; el.onerror = r; setTimeout(r, 800); });
      URL.revokeObjectURL(url);
      return;
    } catch (e) {
      console.warn('[setSinkId beep] failed -> fallback', e);
    }
  }

  // Fallback: oscillator on system output.
  const ctx = ensureAudioContext();
  const osc = ctx.createOscillator();
  const g = ctx.createGain();
  g.gain.value = 0.18;
  osc.type = 'sine';
  osc.frequency.value = 1200;
  osc.connect(g).connect(ctx.destination);
  const now = ctx.currentTime;
  osc.start(now);
  osc.stop(now + 0.35);
  await new Promise(r => setTimeout(r, 400));
}

// -------------------------------
// Sweep generation & inverse filter
// -------------------------------
function makeLogSweepBuffer(context, durationSec, f1, f2, gain) {
  // Exponential sine sweep (Farina-style). Gain is [0..1].
  const sr = context.sampleRate;
  const len = Math.floor(durationSec * sr);
  const buf = context.createBuffer(1, len, sr);
  const out = buf.getChannelData(0);

  const L = Math.log(f2 / f1);
  const K = (2 * Math.PI * f1 * durationSec) / L;

  // Small fade to avoid "click" at start/end.
  const fadeSamples = Math.floor(sr * 0.01);

  for (let n = 0; n < len; n++) {
    const t = n / sr;
    const phase = K * (Math.exp((t / durationSec) * L) - 1);
    let v = Math.sin(phase);

    // Apply fade in/out
    let env = 1.0;
    if (n < fadeSamples) env *= (n / fadeSamples);
    if (n > len - fadeSamples) env *= ((len - n) / fadeSamples);

    out[n] = v * env * gain;
  }

  return buf;
}

function buildInverseSweep(sweepBuffer, durationSec, f1, f2) {
  // Correct inverse for exponential sine sweep:
  // inverse(t) = sweep(T - t) * exp(-t * ln(f2/f1) / T)
  // This compensates the time-varying frequency density.
  const sr = sweepBuffer.sampleRate;
  const len = sweepBuffer.length;
  const s = sweepBuffer.getChannelData(0);

  const inv = new Float32Array(len);
  const L = Math.log(f2 / f1);

  for (let i = 0; i < len; i++) {
    const t = i / sr;
    const w = Math.exp(-t * (L / durationSec));
    inv[i] = s[len - 1 - i] * w;
  }

  // Optional normalization helps numeric stability.
  let mx = 1e-12;
  for (let i = 0; i < len; i++) mx = Math.max(mx, Math.abs(inv[i]));
  for (let i = 0; i < len; i++) inv[i] /= mx;

  return inv;
}

// -------------------------------
// FFT + convolution (fix bug in original FFT)
// -------------------------------
function nextPow2(n) {
  let p = 1;
  while (p < n) p <<= 1;
  return p;
}

function fft(re, im, inverse) {
  // In-place radix-2 Cooley-Tukey FFT.
  // BUGFIX: original code had wrong imaginary part computation.
  const n = re.length;

  // Bit-reversal permutation
  for (let i = 1, j = 0; i < n; i++) {
    let bit = n >> 1;
    for (; j & bit; bit >>= 1) j ^= bit;
    j ^= bit;
    if (i < j) {
      const tr = re[i]; re[i] = re[j]; re[j] = tr;
      const ti = im[i]; im[i] = im[j]; im[j] = ti;
    }
  }

  for (let len = 2; len <= n; len <<= 1) {
    const ang = 2 * Math.PI / len * (inverse ? -1 : 1);
    const wlen_r = Math.cos(ang);
    const wlen_i = Math.sin(ang);

    for (let i = 0; i < n; i += len) {
      let wr = 1, wi = 0;
      for (let k = 0; k < len / 2; k++) {
        const u_r = re[i + k];
        const u_i = im[i + k];

        const v_r = re[i + k + len / 2] * wr - im[i + k + len / 2] * wi;
        const v_i = re[i + k + len / 2] * wi + im[i + k + len / 2] * wr; // <-- FIX

        re[i + k] = u_r + v_r;
        im[i + k] = u_i + v_i;

        re[i + k + len / 2] = u_r - v_r;
        im[i + k + len / 2] = u_i - v_i;

        const tmp = wr * wlen_r - wi * wlen_i;
        wi = wr * wlen_i + wi * wlen_r;
        wr = tmp;
      }
    }
  }

  if (inverse) {
    for (let i = 0; i < n; i++) { re[i] /= n; im[i] /= n; }
  }
}

function convolve(a, b) {
  // FFT-based convolution
  const n = nextPow2(a.length + b.length - 1);
  const ar = new Float32Array(n), ai = new Float32Array(n);
  const br = new Float32Array(n), bi = new Float32Array(n);

  ar.set(a);
  br.set(b);

  fft(ar, ai, false);
  fft(br, bi, false);

  for (let i = 0; i < n; i++) {
    const rr = ar[i] * br[i] - ai[i] * bi[i];
    const ii = ar[i] * bi[i] + ai[i] * br[i];
    ar[i] = rr;
    ai[i] = ii;
  }

  fft(ar, ai, true);
  return ar.subarray(0, a.length + b.length - 1);
}

// -------------------------------
// Recording (ScriptProcessor with safe connection; fallback MediaRecorder)
// -------------------------------
let currentRecorder = null;

async function startRecorderForDevice(virtualDeviceId) {
  await resumeAudioIfNeeded();

  // Stop previous measurement stream if any
  if (currentStream) {
    try { currentStream.getTracks().forEach(t => t.stop()); } catch {}
    currentStream = null;
  }

  const { deviceId, channel } = parseVirtualDeviceId(virtualDeviceId);

  const constraints = {
    audio: {
      deviceId: deviceId ? { exact: deviceId } : undefined,
      // We do NOT force sampleRate here: browser may ignore / resample anyway.
      echoCancellation: false,
      noiseSuppression: false,
      autoGainControl: false
    }
  };

  const stream = await navigator.mediaDevices.getUserMedia(constraints);
  currentStream = stream;

  const ctx = ensureAudioContext();

  // Preferred path: ScriptProcessor (deprecated but still widely supported and easiest to keep offline single-file).
  // We connect to a gain=0 node to keep processing alive without audible feedback.
  if (typeof ctx.createScriptProcessor === 'function') {
    const source = ctx.createMediaStreamSource(stream);
    const proc = ctx.createScriptProcessor(4096, 1, 1);
    const silent = ctx.createGain();
    silent.gain.value = 0.0;

    const chunks = [];
    let total = 0;

    // Route selected channel if requested
    if (channel !== null) {
      const splitter = ctx.createChannelSplitter(2);
      source.connect(splitter);
      const chIndex = (channel === 1) ? 1 : 0;
      splitter.connect(proc, chIndex, 0);
    } else {
      source.connect(proc);
    }

    proc.onaudioprocess = (e) => {
      // Copy buffer NOW because the underlying AudioBuffer is reused by the browser.
      const input = e.inputBuffer.getChannelData(0);
      const copy = new Float32Array(input.length);
      copy.set(input);
      chunks.push(copy);
      total += copy.length;
    };

    // Keep node alive without playing mic to speakers
    proc.connect(silent);
    silent.connect(ctx.destination);

    currentRecorder = {
      stop: async () => {
        // Clean graph
        try { proc.disconnect(); silent.disconnect(); source.disconnect(); } catch {}
        proc.onaudioprocess = null;

        // Stop tracks
        try { stream.getTracks().forEach(t => t.stop()); } catch {}
        currentStream = null;

        // Concatenate
        const out = new Float32Array(total);
        let off = 0;
        for (const c of chunks) { out.set(c, off); off += c.length; }

        currentRecorder = null;
        return out;
      }
    };

    return currentRecorder;
  }

  // Fallback: MediaRecorder (not available on some iOS Safari versions)
  return await new Promise((resolve, reject) => {
    try {
      const mime = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : (MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : '');

      const mr = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
      const data = [];

      mr.ondataavailable = e => { if (e.data && e.data.size) data.push(e.data); };
      mr.onerror = (e) => console.warn('[MediaRecorder] error', e);

      mr.start();

      resolve({
        stop: async () => new Promise(res => {
          mr.onstop = async () => {
            try {
              const blob = new Blob(data, { type: mime || 'audio/webm' });
              const ab = await blob.arrayBuffer();
              const decoded = await ctx.decodeAudioData(ab.slice(0));
              const out = new Float32Array(decoded.getChannelData(0));
              res(out);
            } catch (e) {
              console.warn('[MediaRecorder decode] failed', e);
              res(new Float32Array());
            } finally {
              try { stream.getTracks().forEach(t => t.stop()); } catch {}
              currentStream = null;
              currentRecorder = null;
            }
          };
          mr.stop();
        })
      });
    } catch (e) {
      reject(e);
    }
  });
}

// Playback via <audio> with setSinkId when possible; else AudioBufferSourceNode
async function playBufferThroughOutput(context, audioBuffer, sinkId) {
  await resumeAudioIfNeeded();

  const canSink = (typeof HTMLMediaElement !== 'undefined') && (typeof HTMLMediaElement.prototype.setSinkId === 'function');

  if (canSink && sinkId && sinkId !== 'default') {
    try {
      const wavBlob = floatToWav(audioBuffer.getChannelData(0), context.sampleRate);
      const url = URL.createObjectURL(wavBlob);
      const el = new Audio();
      await el.setSinkId(sinkId);
      el.src = url;
      await el.play();
      await new Promise(r => { el.onended = r; el.onerror = r; });
      URL.revokeObjectURL(url);
      return;
    } catch (e) {
      console.warn('[setSinkId playback] failed -> fallback', e);
    }
  }

  return await new Promise(res => {
    const src = context.createBufferSource();
    src.buffer = audioBuffer;
    src.connect(context.destination);
    src.start();
    src.onended = res;
  });
}

// -------------------------------
// IR + FR computation, alignment, quality metrics
// -------------------------------
function findAbsPeakIndex(x) {
  let idx = 0;
  let mx = -Infinity;
  for (let i = 0; i < x.length; i++) {
    const a = Math.abs(x[i]);
    if (a > mx) { mx = a; idx = i; }
  }
  return idx;
}

function windowAroundPeak(rir, sr, windowSec, preSec) {
  // Return fixed-length window around the main impulse.
  const winLen = Math.max(256, Math.floor(windowSec * sr));
  const pre = Math.floor(preSec * sr);

  const peak = findAbsPeakIndex(rir);
  const start = clamp(peak - pre, 0, Math.max(0, rir.length - 1));
  const out = new Float32Array(winLen);

  for (let i = 0; i < winLen; i++) {
    const src = start + i;
    out[i] = (src < rir.length) ? rir[src] : 0;
  }
  return { window: out, peakIndex: peak, windowStart: start };
}

function computeFreqMag(irWindow) {
  const n = nextPow2(irWindow.length);
  const re = new Float32Array(n);
  const im = new Float32Array(n);
  re.set(irWindow);

  fft(re, im, false);
  const half = n / 2;
  const mags = new Float32Array(half);

  let maxM = 1e-12;
  for (let i = 0; i < half; i++) {
    const m = Math.hypot(re[i], im[i]);
    mags[i] = m;
    if (m > maxM) maxM = m;
  }

  // Normalize to max=1 so different runs are comparable visually.
  for (let i = 0; i < half; i++) mags[i] /= maxM;

  return mags;
}

function computeQuality(raw, irWindow, sr) {
  // Simple quality metrics:
  // - clipping: percentage of samples near +/-1
  // - SNR proxy: peak(IR) / RMS(noise in first 20ms)
  let clipCount = 0;
  for (let i = 0; i < raw.length; i++) if (Math.abs(raw[i]) >= 0.98) clipCount++;
  const clipPct = 100 * (clipCount / Math.max(1, raw.length));

  const peak = Math.max(...irWindow.map(v => Math.abs(v)));
  const noiseLen = Math.max(16, Math.floor(0.02 * sr));
  let sum2 = 0;
  for (let i = 0; i < Math.min(noiseLen, irWindow.length); i++) sum2 += irWindow[i] * irWindow[i];
  const rms = Math.sqrt(sum2 / Math.max(1, Math.min(noiseLen, irWindow.length)));

  const snr = 20 * Math.log10((peak + 1e-12) / (rms + 1e-12));
  return { clipPct, snrDb: snr };
}

function computeIRFromRecording(recorded, sweepBuffer, sweepMeta) {
  const { durationSec, f1, f2 } = sweepMeta;

  // Deconvolution: record * inverseSweep
  const inv = buildInverseSweep(sweepBuffer, durationSec, f1, f2);
  const rirFull = convolve(recorded, inv);

  // Normalize full IR for numeric stability (keep full for export if needed)
  let mx = 1e-12;
  for (let i = 0; i < rirFull.length; i++) mx = Math.max(mx, Math.abs(rirFull[i]));
  for (let i = 0; i < rirFull.length; i++) rirFull[i] /= mx;

  // Window around peak for averaging/features
  const { window: rirWin, peakIndex, windowStart } = windowAroundPeak(rirFull, audioContext.sampleRate, IR_WINDOW_SEC, IR_PRE_SEC);

  // Frequency magnitude from window
  const freq = computeFreqMag(rirWin);

  return { rirFull, rirWin, freq, peakIndex, windowStart };
}

// -------------------------------
// Drawing helpers
// -------------------------------
function drawLine(canvas, data, opts = {}) {
  const ctx = canvas.getContext('2d');
  const w = canvas.width, h = canvas.height;
  ctx.clearRect(0, 0, w, h);
  ctx.fillStyle = '#071022';
  ctx.fillRect(0, 0, w, h);

  const color = opts.color || '#60a5fa';

  // Auto-scale in Y based on percentiles (robust vs outliers).
  let mn = Infinity, mx = -Infinity;
  for (let i = 0; i < data.length; i++) { mn = Math.min(mn, data[i]); mx = Math.max(mx, data[i]); }
  const span = Math.max(1e-9, mx - mn);

  ctx.strokeStyle = color;
  ctx.lineWidth = 1.35;
  ctx.beginPath();
  for (let x = 0; x < w; x++) {
    const idx = Math.floor(x * data.length / w);
    const v = data[idx] || 0;
    // Map v from [mn..mx] to [h..0]
    const y = (1 - ((v - mn) / span)) * (h * 0.85) + (h * 0.075);
    if (x) ctx.lineTo(x, y); else ctx.moveTo(x, y);
  }
  ctx.stroke();

  ctx.fillStyle = 'rgba(255,255,255,0.75)';
  ctx.font = '12px system-ui';
  if (opts.title) ctx.fillText(opts.title, 8, 14);
}

function drawFreqMag(canvas, mags, opts = {}) {
  // Convert normalized mags to dB relative to max (0 dB at peak)
  const db = new Float32Array(mags.length);
  for (let i = 0; i < mags.length; i++) db[i] = 20 * Math.log10(mags[i] + 1e-12); // <= 0

  const ctx = canvas.getContext('2d');
  const w = canvas.width, h = canvas.height;
  ctx.clearRect(0, 0, w, h);
  ctx.fillStyle = '#071022';
  ctx.fillRect(0, 0, w, h);

  const color = opts.color || '#34d399';

  // Plot with fixed dB range for easy comparison
  const minDb = -60; // show [-60..0]
  ctx.strokeStyle = color;
  ctx.lineWidth = 1.35;
  ctx.beginPath();
  for (let x = 0; x < w; x++) {
    const idx = Math.floor(x * db.length / w);
    const v = clamp(db[idx], minDb, 0);
    const y = (1 - ((v - minDb) / (0 - minDb))) * h;
    if (x) ctx.lineTo(x, y); else ctx.moveTo(x, y);
  }
  ctx.stroke();

  ctx.fillStyle = 'rgba(255,255,255,0.75)';
  ctx.font = '12px system-ui';
  if (opts.title) ctx.fillText(opts.title, 8, 14);
}

function drawComparison(canvas, a, b, opts = {}) {
  const ctx = canvas.getContext('2d');
  const w = canvas.width, h = canvas.height;
  ctx.clearRect(0, 0, w, h);
  ctx.fillStyle = '#071022';
  ctx.fillRect(0, 0, w, h);

  const len = Math.min(a.length, b.length);

  function plot(data, color) {
    ctx.strokeStyle = color;
    ctx.lineWidth = 1.35;
    ctx.beginPath();
    for (let x = 0; x < w; x++) {
      const idx = Math.floor(x * len / w);
      const v = data[idx] || 0;
      const y = (0.5 - v * 0.42) * h;
      if (x) ctx.lineTo(x, y); else ctx.moveTo(x, y);
    }
    ctx.stroke();
  }

  plot(a, '#60a5fa');
  plot(b, '#ef4444');

  ctx.fillStyle = 'rgba(255,255,255,0.8)';
  ctx.font = '12px system-ui';
  if (opts.title) ctx.fillText(opts.title, 8, 14);

  // legend
  ctx.fillStyle = '#60a5fa'; ctx.fillRect(w - 170, 10, 10, 10);
  ctx.fillStyle = '#e6eef8'; ctx.fillText('Calibrazione', w - 154, 19);
  ctx.fillStyle = '#ef4444'; ctx.fillRect(w - 170, 28, 10, 10);
  ctx.fillStyle = '#e6eef8'; ctx.fillText('Frutto', w - 154, 37);
}

function drawComparisonFreq(canvas, aMag, bMag, opts = {}) {
  const len = Math.min(aMag.length, bMag.length);
  const a = aMag.subarray(0, len);
  const b = bMag.subarray(0, len);

  const ctx = canvas.getContext('2d');
  const w = canvas.width, h = canvas.height;
  ctx.clearRect(0, 0, w, h);
  ctx.fillStyle = '#071022';
  ctx.fillRect(0, 0, w, h);

  // Convert to dB
  const minDb = -60;
  function plot(mags, color) {
    ctx.strokeStyle = color;
    ctx.lineWidth = 1.35;
    ctx.beginPath();
    for (let x = 0; x < w; x++) {
      const idx = Math.floor(x * mags.length / w);
      const v = clamp(20 * Math.log10(mags[idx] + 1e-12), minDb, 0);
      const y = (1 - ((v - minDb) / (0 - minDb))) * h;
      if (x) ctx.lineTo(x, y); else ctx.moveTo(x, y);
    }
    ctx.stroke();
  }

  plot(a, '#60a5fa');
  plot(b, '#ef4444');

  ctx.fillStyle = 'rgba(255,255,255,0.8)';
  ctx.font = '12px system-ui';
  if (opts.title) ctx.fillText(opts.title, 8, 14);

  ctx.fillStyle = '#60a5fa'; ctx.fillRect(w - 170, 10, 10, 10);
  ctx.fillStyle = '#e6eef8'; ctx.fillText('Calibrazione (dB)', w - 154, 19);
  ctx.fillStyle = '#ef4444'; ctx.fillRect(w - 170, 28, 10, 10);
  ctx.fillStyle = '#e6eef8'; ctx.fillText('Frutto (dB)', w - 154, 37);
}

// -------------------------------
// Measurement pipeline
// -------------------------------
async function performMeasurement(params) {
  // IMPORTANT: we aim for consistent buffer lengths.
  // The actual recorded length can vary slightly (timer granularity, buffering). We normalize with resizeToLength.
  await resumeAudioIfNeeded();

  const deviceIn = params.deviceIn;
  const deviceOut = params.deviceOut;
  const delaySec = Math.max(0, params.delaySec);
  const sweepSec = Math.max(0.2, params.sweepSec);
  const tailSec = Math.max(0, params.tailSec);
  const f1 = Math.max(10, params.f1);
  const f2 = Math.max(f1 + 10, params.f2);
  const sweepGain = clamp(params.sweepGain, 0.02, 1.0);

  const ctx = ensureAudioContext();

  const sweepBuf = makeLogSweepBuffer(ctx, sweepSec, f1, f2, sweepGain);
  const recorder = await startRecorderForDevice(deviceIn);

  // Use context time for a more stable schedule vs setTimeout-only.
  // We still await with setTimeout for UI simplicity, then normalize length.
  const recordDuration = delaySec + sweepSec + tailSec;

  // Delay before sweep
  await new Promise(r => setTimeout(r, delaySec * 1000));

  // Play sweep
  await playBufferThroughOutput(ctx, sweepBuf, deviceOut);

  // Tail after sweep (captures ringing)
  await new Promise(r => setTimeout(r, tailSec * 1000));

  // Stop recording
  const recorded = await recorder.stop();

  // Normalize length (this prevents NaN during averaging)
  const targetSamples = Math.max(1, Math.round(recordDuration * ctx.sampleRate));
  const rawFixed = resizeToLength(recorded, targetSamples);

  return {
    raw: rawFixed,
    sweepBuffer: sweepBuf,
    sweepMeta: { durationSec: sweepSec, f1, f2, delaySec, tailSec, sweepGain, sampleRate: ctx.sampleRate }
  };
}

// -------------------------------
// CSV export (small "feature vector")
// -------------------------------
function computeFeatureVector(calMag, measMag) {
  // Very simple “feature”: difference in band-energies (dB) for a few bands.
  // In a real app you would train a model; here we export something stable and comparable.
  const bands = [
    { name:'250-500Hz',  f1:250,  f2:500  },
    { name:'500-1kHz',   f1:500,  f2:1000 },
    { name:'1-2kHz',     f1:1000, f2:2000 },
    { name:'2-4kHz',     f1:2000, f2:4000 },
    { name:'4-8kHz',     f1:4000, f2:8000 }
  ];

  const sr = audioContext.sampleRate;
  const nfft = (calMag.length - 1) * 2;
  const hzPerBin = sr / nfft;

  function bandAvgDb(mag, f1, f2) {
    const i1 = clamp(Math.floor(f1 / hzPerBin), 0, mag.length - 1);
    const i2 = clamp(Math.floor(f2 / hzPerBin), 0, mag.length - 1);
    let sum = 0;
    let cnt = 0;
    for (let i = i1; i <= i2; i++) {
      sum += 20 * Math.log10(mag[i] + 1e-12);
      cnt++;
    }
    return sum / Math.max(1, cnt);
  }

  const rows = [];
  for (const b of bands) {
    const calDb = bandAvgDb(calMag, b.f1, b.f2);
    const measDb = bandAvgDb(measMag, b.f1, b.f2);
    rows.push({ band: b.name, cal_db: calDb, fruit_db: measDb, diff_db: (measDb - calDb) });
  }
  return rows;
}

// -------------------------------
// UI event wiring
// -------------------------------
requestPermBtn.addEventListener('click', requestPermissions);

startAppBtn.addEventListener('click', async () => {
  await stopMicMonitor();
  showStage(1);
});

backBtn.addEventListener('click', async () => {
  await resetAllState();
  showStage(0);
});

inputSelect.addEventListener('change', async (e) => {
  updateStartEnabled();
  if (e.target.value) await startMicMonitor(e.target.value);
});

outputSelect.addEventListener('change', () => {
  // Nothing required; selection is used when setSinkId exists.
});

playTestSoundBtn.addEventListener('click', async () => {
  await playTestBeepForSink(outputSelect.value || 'default');
});

stopMicTestBtn.addEventListener('click', stopMicMonitor);

// Stage 1
startCalBtn.addEventListener('click', async () => {
  addCalRunBtn.disabled = true;
  continueToMeasureBtn.disabled = true;
  calLoader.classList.add('show');

  try {
    const params = readParamsFromUI();
    const { raw, sweepBuffer, sweepMeta } = await performMeasurement(params);

    const ir = computeIRFromRecording(raw, sweepBuffer, sweepMeta);
    const q = computeQuality(raw, ir.rirWin, audioContext.sampleRate);

    calRuns.push({
      raw,
      rir: ir.rirWin,        // windowed, fixed length for averaging
      freq: ir.freq,         // normalized magnitude
      meta: { ...sweepMeta, quality: q, peakIndex: ir.peakIndex, windowStart: ir.windowStart }
    });

    updateRunCounters();

    // Plot latest raw and averaged IR/FR
    const avgIR = averageFloatArrays(calRuns.map(r => r.rir));
    const avgFR = averageFloatArrays(calRuns.map(r => r.freq));

    drawLine(calRawCanvas, raw, { title: 'Calibrazione — raw (time)', color: '#60a5fa' });
    drawLine(calIRTimeCanvas, avgIR, { title: 'Calibrazione — IR (media)', color: '#60a5fa' });
    drawFreqMag(calIRFreqCanvas, avgFR, { title: 'Calibrazione — FR (dB, normalizzato)', color: '#34d399' });

    calPlots.classList.remove('hidden');

    // Quality text
    calQuality.innerHTML = qualityText(q);

    addCalRunBtn.disabled = false;
    continueToMeasureBtn.disabled = false;
  } catch (e) {
    console.warn('[calibration] failed', e);
    alert('Calibrazione fallita: ' + (e.message || e));
  } finally {
    calLoader.classList.remove('show');
  }
});

addCalRunBtn.addEventListener('click', () => startCalBtn.click());

resetCalRunsBtn.addEventListener('click', () => {
  calRuns = [];
  updateRunCounters();
  calQuality.textContent = '';
  calPlots.classList.add('hidden');
  clearCanvas(calRawCanvas);
  clearCanvas(calIRTimeCanvas);
  clearCanvas(calIRFreqCanvas);
  continueToMeasureBtn.disabled = true;
  addCalRunBtn.disabled = true;
});

continueToMeasureBtn.addEventListener('click', () => showStage(2));

// Stage 2
startMeasBtn.addEventListener('click', async () => {
  addMeasRunBtn.disabled = true;
  continueToCompareBtn.disabled = true;
  measLoader.classList.add('show');

  try {
    const params = readParamsFromUI();
    const { raw, sweepBuffer, sweepMeta } = await performMeasurement(params);

    const ir = computeIRFromRecording(raw, sweepBuffer, sweepMeta);
    const q = computeQuality(raw, ir.rirWin, audioContext.sampleRate);

    measRuns.push({
      raw,
      rir: ir.rirWin,
      freq: ir.freq,
      meta: { ...sweepMeta, quality: q, peakIndex: ir.peakIndex, windowStart: ir.windowStart }
    });

    updateRunCounters();

    const avgIR = averageFloatArrays(measRuns.map(r => r.rir));
    const avgFR = averageFloatArrays(measRuns.map(r => r.freq));

    drawLine(measRawCanvas, raw, { title: 'Frutto — raw (time)', color: '#ef4444' });
    drawLine(measIRTimeCanvas, avgIR, { title: 'Frutto — IR (media)', color: '#ef4444' });
    drawFreqMag(measIRFreqCanvas, avgFR, { title: 'Frutto — FR (dB, normalizzato)', color: '#ef4444' });

    measPlots.classList.remove('hidden');

    measQuality.innerHTML = qualityText(q);

    addMeasRunBtn.disabled = false;
    continueToCompareBtn.disabled = false;
  } catch (e) {
    console.warn('[measurement] failed', e);
    alert('Misura fallita: ' + (e.message || e));
  } finally {
    measLoader.classList.remove('show');
  }
});

addMeasRunBtn.addEventListener('click', () => startMeasBtn.click());

resetMeasRunsBtn.addEventListener('click', () => {
  measRuns = [];
  updateRunCounters();
  measQuality.textContent = '';
  measPlots.classList.add('hidden');
  clearCanvas(measRawCanvas);
  clearCanvas(measIRTimeCanvas);
  clearCanvas(measIRFreqCanvas);
  continueToCompareBtn.disabled = true;
  addMeasRunBtn.disabled = true;
});

continueToCompareBtn.addEventListener('click', () => {
  if (!calRuns.length || !measRuns.length) {
    alert('Esegui almeno 1 run di calibrazione e 1 run sul frutto.');
    return;
  }

  const avgCalIR = averageFloatArrays(calRuns.map(r => r.rir));
  const avgMeasIR = averageFloatArrays(measRuns.map(r => r.rir));

  const avgCalFR = averageFloatArrays(calRuns.map(r => r.freq));
  const avgMeasFR = averageFloatArrays(measRuns.map(r => r.freq));

  drawComparison(cmpIR, avgCalIR, avgMeasIR, { title: 'IR (time): Calibrazione vs Frutto' });
  drawComparisonFreq(cmpFR, avgCalFR, avgMeasFR, { title: 'FR (dB): Calibrazione vs Frutto' });

  // Build export payload (keep arrays bounded to avoid huge JSON)
  const payload = buildExportPayload(avgCalIR, avgCalFR, avgMeasIR, avgMeasFR);
  jsonPreview.textContent = JSON.stringify(payload, null, 2);

  showStage(3);
});

// Stage 3 slider
ripenessSlider.addEventListener('input', () => { ripenessVal.textContent = ripenessSlider.value; });

// Download JSON
downloadJsonBtn.addEventListener('click', () => {
  const payload = JSON.parse(jsonPreview.textContent || '{}');
  payload.ripeness = Number(ripenessSlider.value);
  payload.timestamp = new Date().toISOString();
  const text = JSON.stringify(payload, null, 2);

  downloadTextFile(text, `rir_fruit_${new Date().toISOString().replace(/[:.]/g, '-')}.json`, 'application/json');
});

// Download CSV (feature vector)
downloadCsvBtn.addEventListener('click', () => {
  if (!calRuns.length || !measRuns.length) return;

  const avgCalFR = averageFloatArrays(calRuns.map(r => r.freq));
  const avgMeasFR = averageFloatArrays(measRuns.map(r => r.freq));

  const rows = computeFeatureVector(avgCalFR, avgMeasFR);
  const header = 'band,cal_db,fruit_db,diff_db\n';
  const lines = rows.map(r => `${r.band},${r.cal_db.toFixed(3)},${r.fruit_db.toFixed(3)},${r.diff_db.toFixed(3)}`).join('\n');
  const csv = header + lines + '\n';

  downloadTextFile(csv, `rir_features_${new Date().toISOString().replace(/[:.]/g, '-')}.csv`, 'text/csv');
});

// -------------------------------
// UI parameter parsing + helpers
// -------------------------------
function readParamsFromUI() {
  const deviceIn = inputSelect.value || 'default';
  const deviceOut = outputSelect.value || 'default';

  const delaySec = parseFloat(delayEl.value) || 0.8;
  const sweepSec = parseFloat(sweepDurationEl.value) || 3.5;
  const tailSec = parseFloat(tailSilenceEl.value) || 0.35;
  const f1 = parseFloat(f1El.value) || 80;
  const f2 = parseFloat(f2El.value) || 9000;
  const sweepGain = (parseFloat(outputGainEl.value) || 45) / 100;

  return { deviceIn, deviceOut, delaySec, sweepSec, tailSec, f1, f2, sweepGain };
}

function qualityText(q) {
  const clipCls = (q.clipPct > 0.5) ? 'danger' : (q.clipPct > 0.05 ? 'warn' : 'ok');
  const snrCls  = (q.snrDb < 12) ? 'warn' : 'ok';

  const clipTxt = `<span class="${clipCls}">Clipping: ${q.clipPct.toFixed(2)}%</span>`;
  const snrTxt  = `<span class="${snrCls}">SNR≈ ${q.snrDb.toFixed(1)} dB</span>`;
  return `${clipTxt} • ${snrTxt}`;
}

function buildExportPayload(avgCalIR, avgCalFR, avgMeasIR, avgMeasFR) {
  // Guard array sizes to keep JSON manageable.
  function toArrayBounded(f32) {
    const trimmed = f32.subarray(0, Math.min(MAX_EXPORT_SAMPLES, f32.length));
    return Array.from(trimmed);
  }

  return {
    version: 'v1.1-fixed',
    timestamp: new Date().toISOString(),
    device: {
      userAgent: navigator.userAgent,
      sampleRate: audioContext ? audioContext.sampleRate : null
    },
    params: readParamsFromUI(),
    ripeness: Number(ripenessSlider.value),
    calibration_ir_window: toArrayBounded(avgCalIR),
    calibration_fr_mag_norm: toArrayBounded(avgCalFR),
    fruit_ir_window: toArrayBounded(avgMeasIR),
    fruit_fr_mag_norm: toArrayBounded(avgMeasFR),
    runs: {
      calibration: calRuns.map(r => ({ meta: r.meta, raw_samples: Math.min(MAX_EXPORT_SAMPLES, r.raw.length) })),
      fruit: measRuns.map(r => ({ meta: r.meta, raw_samples: Math.min(MAX_EXPORT_SAMPLES, r.raw.length) }))
    }
  };
}

function downloadTextFile(text, filename, mime) {
  const blob = new Blob([text], { type: mime });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  a.remove();
  URL.revokeObjectURL(url);
}

// -------------------------------
// Reset all state (Back)
// -------------------------------
async function resetAllState() {
  await stopMicMonitor();

  if (currentStream) { try { currentStream.getTracks().forEach(t => t.stop()); } catch {} currentStream = null; }
  if (audioContext) {
    try { await audioContext.close(); } catch {}
    audioContext = null;
  }

  calRuns = [];
  measRuns = [];
  updateRunCounters();

  // reset UI
  calQuality.textContent = '';
  measQuality.textContent = '';
  calPlots.classList.add('hidden');
  measPlots.classList.add('hidden');
  calLoader.classList.remove('show');
  measLoader.classList.remove('show');

  continueToMeasureBtn.disabled = true;
  addCalRunBtn.disabled = true;
  continueToCompareBtn.disabled = true;
  addMeasRunBtn.disabled = true;

  clearCanvas(calRawCanvas);
  clearCanvas(calIRTimeCanvas);
  clearCanvas(calIRFreqCanvas);
  clearCanvas(measRawCanvas);
  clearCanvas(measIRTimeCanvas);
  clearCanvas(measIRFreqCanvas);
  clearCanvas(cmpIR);
  clearCanvas(cmpFR);

  jsonPreview.textContent = '';

  micTest.classList.add('hidden');
  permStatus.textContent = 'In attesa dei permessi microfono.';

  ripenessSlider.value = 5;
  ripenessVal.textContent = '5';

  updateCompatibilityPills();
  await enumerateDevices();
  updateStartEnabled();
}

// -------------------------------
// Initial boot
// -------------------------------
(async function init() {
  updateRunCounters();
  // Pre-fill device lists (labels may be empty before permission)
  await enumerateDevices();

  // Enable start if we have at least a default mic option.
  if (!inputSelect.value && inputSelect.options.length) inputSelect.value = inputSelect.options[0].value;

  updateStartEnabled();
})();
</script>
</body>
</html>
